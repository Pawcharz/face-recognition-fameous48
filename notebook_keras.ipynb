{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras import Sequential, Input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "from utils.constrains import CLASSES, IMAGE_SIZE\n",
    "from utils.load_dataset import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the result reproducible\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices(physical_devices[1], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes description\n",
    "\n",
    "- a1 - face containing flag: (1-with face, 0-without face),\n",
    "- a2 - image number in current class (person) beginning from 0,\n",
    "- a3 - class (person) number beginning from 0,\n",
    "- a4 - sex (0 - woman, 1 - man)\n",
    "- a5 - race (0- white, 1 - negro, 2 - indian, ...)\n",
    "- a6 - age (0 - baby, 1 - young, 2 - middle-age, 3 - old) \n",
    "- a7 - binokulars (0 - without, 1 - transparent, 2 - dark)\n",
    "- a8 - emotional expression (not state!) (0 - sad, 1 - neutral, 2 - happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRPATH = './data'\n",
    "X_train, X_test, y_train, y_test = load_dataset(DIRPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing LeNet-5 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 12, 12, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 12, 12, 6)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 16)        2416      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 6, 6, 16)          0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 120)         48120     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4320)              0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 4320)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                362964    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 48)                4080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 417,736\n",
      "Trainable params: 417,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# conv_regularizer = regularizers.l2(0.0006)\n",
    "# dense_regularizer = regularizers.l2(0.01)\n",
    "\n",
    "conv_regularizer = regularizers.l2(0.0009096443481619992)\n",
    "dense_regularizer = regularizers.l2(0.011905583599301073)\n",
    "\n",
    "# activation_def = 'tanh'\n",
    "\n",
    "dropout_base = 0.09439855997376015\n",
    "dropout_inc = 0.14131761625994724\n",
    "dropout_1 = dropout_base\n",
    "dropout_2 = dropout_base + dropout_inc\n",
    "dropout_3 = dropout_base + 2*dropout_inc\n",
    "\n",
    "DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=5, padding=\"same\", activation=\"tanh\",\n",
    "                        kernel_regularizer=conv_regularizer) # kernel_initializer=\"he_normal\")\n",
    "\n",
    "model = Sequential(\n",
    "  [\n",
    "    Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
    "    DefaultConv2D(6),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "\n",
    "    layers.Dropout(dropout_1),\n",
    "    DefaultConv2D(16),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "\n",
    "    layers.Dropout(dropout_2),\n",
    "    DefaultConv2D(120),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(dropout_3),\n",
    "    layers.Dense(84, activation=activation_def, kernel_regularizer=dense_regularizer),\n",
    "    layers.Dense(CLASSES, activation='softmax'),\n",
    "  ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lr_metric(optimizer):\n",
    "#   def lr(y_true, y_pred):\n",
    "#     return optimizer._decayed_lr(tf.float32) # I use ._decayed_lr method instead of .lr\n",
    "#   return lr\n",
    "\n",
    "# lr_metric = get_lr_metric(optimizer)\n",
    "# model.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=[\"accuracy\", lr_metric])\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step_decay(epoch):\n",
    "#   initial_lrate = 0.1\n",
    "#   drop = 0.9\n",
    "#   epochs_drop = 10.0\n",
    "#   lrate = initial_lrate * math.pow(drop,  \n",
    "#           math.floor((1+epoch)/epochs_drop))\n",
    "#   return lrate\n",
    " \n",
    "# lrate_scheduler_callback = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'models/checkpoints/famous48_test_model_v2_best.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "  filepath=CHECKPOINT_PATH,\n",
    "  save_weights_only=False,\n",
    "  monitor='val_accuracy',\n",
    "  mode='max',\n",
    "  save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 4.9319 - accuracy: 0.0663 - val_loss: 4.2841 - val_accuracy: 0.1197\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 3.6980 - accuracy: 0.2218 - val_loss: 3.2366 - val_accuracy: 0.2797\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 2.9385 - accuracy: 0.3487 - val_loss: 2.7531 - val_accuracy: 0.3647\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.5687 - accuracy: 0.4326 - val_loss: 2.4916 - val_accuracy: 0.4260\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.3682 - accuracy: 0.4783 - val_loss: 2.2455 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.2025 - accuracy: 0.5206 - val_loss: 2.1267 - val_accuracy: 0.5439\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.0991 - accuracy: 0.5455 - val_loss: 2.0245 - val_accuracy: 0.5612\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.9938 - accuracy: 0.5770 - val_loss: 1.9112 - val_accuracy: 0.5896\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.9168 - accuracy: 0.5882 - val_loss: 1.8796 - val_accuracy: 0.5859\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.8384 - accuracy: 0.6161 - val_loss: 1.8114 - val_accuracy: 0.6207\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.7658 - accuracy: 0.6287 - val_loss: 1.7500 - val_accuracy: 0.6325\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.7366 - accuracy: 0.6331 - val_loss: 1.6728 - val_accuracy: 0.6554\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.6699 - accuracy: 0.6559 - val_loss: 1.6174 - val_accuracy: 0.6700\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.6213 - accuracy: 0.6783 - val_loss: 1.6152 - val_accuracy: 0.6618\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.5945 - accuracy: 0.6824 - val_loss: 1.5949 - val_accuracy: 0.6718\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.5654 - accuracy: 0.6824 - val_loss: 1.5311 - val_accuracy: 0.6901\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.5188 - accuracy: 0.6982 - val_loss: 1.4991 - val_accuracy: 0.6938\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4857 - accuracy: 0.6968 - val_loss: 1.4796 - val_accuracy: 0.7057\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.4667 - accuracy: 0.7085 - val_loss: 1.4524 - val_accuracy: 0.7121\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4470 - accuracy: 0.7128 - val_loss: 1.4630 - val_accuracy: 0.7020\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4051 - accuracy: 0.7284 - val_loss: 1.3991 - val_accuracy: 0.7230\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.3958 - accuracy: 0.7295 - val_loss: 1.3707 - val_accuracy: 0.7322\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.3623 - accuracy: 0.7417 - val_loss: 1.3883 - val_accuracy: 0.7166\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.3364 - accuracy: 0.7412 - val_loss: 1.3512 - val_accuracy: 0.7386\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.3337 - accuracy: 0.7435 - val_loss: 1.3449 - val_accuracy: 0.7267\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.3027 - accuracy: 0.7542 - val_loss: 1.2910 - val_accuracy: 0.7486\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2697 - accuracy: 0.7668 - val_loss: 1.2875 - val_accuracy: 0.7404\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2697 - accuracy: 0.7629 - val_loss: 1.3440 - val_accuracy: 0.7276\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.2662 - accuracy: 0.7618 - val_loss: 1.3258 - val_accuracy: 0.7386\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.2509 - accuracy: 0.7721 - val_loss: 1.2771 - val_accuracy: 0.7422\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.2287 - accuracy: 0.7773 - val_loss: 1.2626 - val_accuracy: 0.7468\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1839 - accuracy: 0.7956 - val_loss: 1.2407 - val_accuracy: 0.7587\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1855 - accuracy: 0.7803 - val_loss: 1.2306 - val_accuracy: 0.7623\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1906 - accuracy: 0.7922 - val_loss: 1.2310 - val_accuracy: 0.7587\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1908 - accuracy: 0.7773 - val_loss: 1.2715 - val_accuracy: 0.7505\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1677 - accuracy: 0.7890 - val_loss: 1.2403 - val_accuracy: 0.7751\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1481 - accuracy: 0.7986 - val_loss: 1.2223 - val_accuracy: 0.7605\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1141 - accuracy: 0.8064 - val_loss: 1.2174 - val_accuracy: 0.7687\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1277 - accuracy: 0.8022 - val_loss: 1.1862 - val_accuracy: 0.7742\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1262 - accuracy: 0.8036 - val_loss: 1.1906 - val_accuracy: 0.7651\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0971 - accuracy: 0.8100 - val_loss: 1.1983 - val_accuracy: 0.7733\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.1013 - accuracy: 0.8080 - val_loss: 1.1683 - val_accuracy: 0.7815\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0906 - accuracy: 0.8052 - val_loss: 1.1697 - val_accuracy: 0.7779\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0808 - accuracy: 0.8146 - val_loss: 1.1722 - val_accuracy: 0.7742\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0845 - accuracy: 0.8130 - val_loss: 1.1732 - val_accuracy: 0.7633\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0664 - accuracy: 0.8182 - val_loss: 1.1775 - val_accuracy: 0.7815\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0595 - accuracy: 0.8285 - val_loss: 1.1352 - val_accuracy: 0.7943\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0425 - accuracy: 0.8258 - val_loss: 1.1466 - val_accuracy: 0.7834\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0319 - accuracy: 0.8315 - val_loss: 1.1476 - val_accuracy: 0.7925\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0482 - accuracy: 0.8208 - val_loss: 1.1326 - val_accuracy: 0.7843\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0128 - accuracy: 0.8418 - val_loss: 1.1556 - val_accuracy: 0.7797\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0029 - accuracy: 0.8413 - val_loss: 1.1177 - val_accuracy: 0.7861\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.0005 - accuracy: 0.8374 - val_loss: 1.1280 - val_accuracy: 0.7843\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9763 - accuracy: 0.8441 - val_loss: 1.1551 - val_accuracy: 0.7834\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9764 - accuracy: 0.8468 - val_loss: 1.1005 - val_accuracy: 0.7934\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9812 - accuracy: 0.8432 - val_loss: 1.1367 - val_accuracy: 0.7834\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9663 - accuracy: 0.8496 - val_loss: 1.1098 - val_accuracy: 0.7971\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9650 - accuracy: 0.8480 - val_loss: 1.0925 - val_accuracy: 0.8053\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9704 - accuracy: 0.8503 - val_loss: 1.1070 - val_accuracy: 0.7962\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9622 - accuracy: 0.8480 - val_loss: 1.0834 - val_accuracy: 0.8117\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9385 - accuracy: 0.8539 - val_loss: 1.0949 - val_accuracy: 0.8016\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9354 - accuracy: 0.8610 - val_loss: 1.0778 - val_accuracy: 0.8144\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9488 - accuracy: 0.8507 - val_loss: 1.1082 - val_accuracy: 0.7971\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9327 - accuracy: 0.8605 - val_loss: 1.0972 - val_accuracy: 0.7989\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9171 - accuracy: 0.8649 - val_loss: 1.0807 - val_accuracy: 0.8044\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9198 - accuracy: 0.8548 - val_loss: 1.1085 - val_accuracy: 0.8062\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9334 - accuracy: 0.8532 - val_loss: 1.0803 - val_accuracy: 0.7916\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9044 - accuracy: 0.8637 - val_loss: 1.0738 - val_accuracy: 0.8026\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8991 - accuracy: 0.8704 - val_loss: 1.1033 - val_accuracy: 0.7925\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8976 - accuracy: 0.8619 - val_loss: 1.0624 - val_accuracy: 0.8044\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9101 - accuracy: 0.8578 - val_loss: 1.0840 - val_accuracy: 0.8126\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8825 - accuracy: 0.8711 - val_loss: 1.0564 - val_accuracy: 0.8108\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8826 - accuracy: 0.8717 - val_loss: 1.0373 - val_accuracy: 0.8135\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9017 - accuracy: 0.8656 - val_loss: 1.0505 - val_accuracy: 0.8053\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8776 - accuracy: 0.8756 - val_loss: 1.0488 - val_accuracy: 0.8099\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8699 - accuracy: 0.8708 - val_loss: 1.0370 - val_accuracy: 0.8245\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8669 - accuracy: 0.8752 - val_loss: 1.0549 - val_accuracy: 0.8144\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8714 - accuracy: 0.8736 - val_loss: 1.0451 - val_accuracy: 0.8135\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8617 - accuracy: 0.8738 - val_loss: 1.0159 - val_accuracy: 0.8236\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8578 - accuracy: 0.8761 - val_loss: 1.0573 - val_accuracy: 0.8154\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8529 - accuracy: 0.8756 - val_loss: 1.0494 - val_accuracy: 0.7998\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8675 - accuracy: 0.8669 - val_loss: 1.0575 - val_accuracy: 0.8117\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8673 - accuracy: 0.8688 - val_loss: 1.0340 - val_accuracy: 0.8135\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8603 - accuracy: 0.8759 - val_loss: 1.0457 - val_accuracy: 0.8053\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8471 - accuracy: 0.8791 - val_loss: 1.0206 - val_accuracy: 0.8218\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8451 - accuracy: 0.8740 - val_loss: 1.0261 - val_accuracy: 0.8172\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8364 - accuracy: 0.8813 - val_loss: 1.0543 - val_accuracy: 0.8044\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.8455 - accuracy: 0.8761 - val_loss: 1.0383 - val_accuracy: 0.8208\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8452 - accuracy: 0.8809 - val_loss: 1.0505 - val_accuracy: 0.8163\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8275 - accuracy: 0.8882 - val_loss: 1.0116 - val_accuracy: 0.8181\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8354 - accuracy: 0.8786 - val_loss: 1.0220 - val_accuracy: 0.8154\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8395 - accuracy: 0.8807 - val_loss: 1.0041 - val_accuracy: 0.8373\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8242 - accuracy: 0.8848 - val_loss: 1.0332 - val_accuracy: 0.8190\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8235 - accuracy: 0.8818 - val_loss: 0.9990 - val_accuracy: 0.8300\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8151 - accuracy: 0.8868 - val_loss: 0.9977 - val_accuracy: 0.8254\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7973 - accuracy: 0.8987 - val_loss: 0.9957 - val_accuracy: 0.8199\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7979 - accuracy: 0.8914 - val_loss: 1.0188 - val_accuracy: 0.8163\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7944 - accuracy: 0.8928 - val_loss: 1.0215 - val_accuracy: 0.8272\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8093 - accuracy: 0.8852 - val_loss: 1.0267 - val_accuracy: 0.8218\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8177 - accuracy: 0.8811 - val_loss: 0.9926 - val_accuracy: 0.8455\n",
      "CPU times: total: 28.4 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 200\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(\n",
    "  X_train, y_train,\n",
    "  batch_size=batch_size,\n",
    "  epochs=epochs,\n",
    "  validation_split=0.2,\n",
    "  shuffle=True,\n",
    "  # callbacks=[model_checkpoint_callback, lrate_scheduler_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accuracy: 0.88\n",
      "validation set accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "length = len(history.history['accuracy'])\n",
    "print(\"train set accuracy:\", round(history.history['accuracy'][length-1], 3))\n",
    "print(\"train loss:\", round(history.history['loss'][length-1], 3))\n",
    "print(\"validation set accuracy:\", round(history.history['val_accuracy'][length-1], 3))\n",
    "print(\"validation set loss:\", round(history.history['val_loss'][length-1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0556 - accuracy: 0.8208\n",
      "test set accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test_fixed)\n",
    "print(\"test set accuracy:\", round(results[1], 3))\n",
    "print(\"test set loss:\", round(results[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
