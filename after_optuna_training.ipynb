{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras import Sequential, Input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "from utils.constants import CLASSES, IMAGE_SIZE\n",
    "from utils.load_dataset import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the result reproducible\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices(physical_devices[1], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes description\n",
    "\n",
    "- a1 - face containing flag: (1-with face, 0-without face),\n",
    "- a2 - image number in current class (person) beginning from 0,\n",
    "- a3 - class (person) number beginning from 0,\n",
    "- a4 - sex (0 - woman, 1 - man)\n",
    "- a5 - race (0- white, 1 - negro, 2 - indian, ...)\n",
    "- a6 - age (0 - baby, 1 - young, 2 - middle-age, 3 - old) \n",
    "- a7 - binokulars (0 - without, 1 - transparent, 2 - dark)\n",
    "- a8 - emotional expression (not state!) (0 - sad, 1 - neutral, 2 - happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRPATH = './data'\n",
    "X_train, X_test, y_train, y_test = load_dataset(DIRPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing LeNet-5 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 12, 12, 6)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 16)        2416      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6, 6, 16)          0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 120)         48120     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4320)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4320)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 84)                362964    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 48)                4080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 417,736\n",
      "Trainable params: 417,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "conv_regularizer = regularizers.l2(0.0006124219567560658)\n",
    "dense_regularizer = regularizers.l2(0.03011157028527752)\n",
    "\n",
    "activation_def = 'tanh'\n",
    "\n",
    "# {'conv_regularizer': 0.0006124219567560658, 'dense_regularizer': 0.03011157028527752, 'dropout_1': 0.3433425343566813, 'dropout_2': 0.1625206873530064, 'dropout_3': 0.019169937499455086}.\n",
    "\n",
    "DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=5, padding=\"same\", activation=activation_def,\n",
    "                        kernel_regularizer=conv_regularizer) # kernel_initializer=\"he_normal\")\n",
    "\n",
    "model = Sequential(\n",
    "  [\n",
    "    Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
    "    DefaultConv2D(6),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "\n",
    "    layers.Dropout(0.3433425343566813),\n",
    "    DefaultConv2D(16),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "\n",
    "    layers.Dropout(0.1625206873530064),\n",
    "    DefaultConv2D(120),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.019169937499455086),\n",
    "    layers.Dense(84, activation=activation_def, kernel_regularizer=dense_regularizer),\n",
    "    layers.Dense(CLASSES, activation='softmax'),\n",
    "  ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lr_metric(optimizer):\n",
    "#   def lr(y_true, y_pred):\n",
    "#     return optimizer._decayed_lr(tf.float32) # I use ._decayed_lr method instead of .lr\n",
    "#   return lr\n",
    "\n",
    "# lr_metric = get_lr_metric(optimizer)\n",
    "# model.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=[\"accuracy\", lr_metric])\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step_decay(epoch):\n",
    "#   initial_lrate = 0.1\n",
    "#   drop = 0.9\n",
    "#   epochs_drop = 10.0\n",
    "#   lrate = initial_lrate * math.pow(drop,  \n",
    "#           math.floor((1+epoch)/epochs_drop))\n",
    "#   return lrate\n",
    " \n",
    "# lrate_scheduler_callback = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'models/checkpoints/famous48_test_model_v2_best.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "  filepath=CHECKPOINT_PATH,\n",
    "  save_weights_only=False,\n",
    "  monitor='val_accuracy',\n",
    "  mode='max',\n",
    "  save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "22/22 [==============================] - 1s 18ms/step - loss: 6.3005 - accuracy: 0.0565 - val_loss: 4.4307 - val_accuracy: 0.0512\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 3.7762 - accuracy: 0.1635 - val_loss: 3.2106 - val_accuracy: 0.2495\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 3.0655 - accuracy: 0.2833 - val_loss: 2.7797 - val_accuracy: 0.3748\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 2.7683 - accuracy: 0.3603 - val_loss: 2.5625 - val_accuracy: 0.3976\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.5773 - accuracy: 0.4081 - val_loss: 2.3970 - val_accuracy: 0.4470\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.4351 - accuracy: 0.4415 - val_loss: 2.3208 - val_accuracy: 0.4580\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.3333 - accuracy: 0.4666 - val_loss: 2.1983 - val_accuracy: 0.4927\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.2335 - accuracy: 0.4984 - val_loss: 2.0876 - val_accuracy: 0.5448\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.1869 - accuracy: 0.5046 - val_loss: 2.0243 - val_accuracy: 0.5393\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.0982 - accuracy: 0.5283 - val_loss: 1.9948 - val_accuracy: 0.5539\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 2.0257 - accuracy: 0.5489 - val_loss: 1.8852 - val_accuracy: 0.5887\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.9639 - accuracy: 0.5754 - val_loss: 1.8703 - val_accuracy: 0.5932\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.9502 - accuracy: 0.5764 - val_loss: 1.8627 - val_accuracy: 0.5759\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.9139 - accuracy: 0.5818 - val_loss: 1.7946 - val_accuracy: 0.6197\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.8821 - accuracy: 0.5837 - val_loss: 1.7538 - val_accuracy: 0.6298\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.8168 - accuracy: 0.6052 - val_loss: 1.6802 - val_accuracy: 0.6444\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.7820 - accuracy: 0.6196 - val_loss: 1.6879 - val_accuracy: 0.6399\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.7445 - accuracy: 0.6278 - val_loss: 1.6436 - val_accuracy: 0.6691\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.7321 - accuracy: 0.6301 - val_loss: 1.6352 - val_accuracy: 0.6490\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.7191 - accuracy: 0.6379 - val_loss: 1.6189 - val_accuracy: 0.6737\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.6612 - accuracy: 0.6470 - val_loss: 1.5488 - val_accuracy: 0.6782\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 1.6416 - accuracy: 0.6477 - val_loss: 1.5501 - val_accuracy: 0.6837\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.6309 - accuracy: 0.6543 - val_loss: 1.5469 - val_accuracy: 0.6801\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.6221 - accuracy: 0.6635 - val_loss: 1.5188 - val_accuracy: 0.6892\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.5890 - accuracy: 0.6692 - val_loss: 1.4922 - val_accuracy: 0.6910\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.5639 - accuracy: 0.6795 - val_loss: 1.5273 - val_accuracy: 0.6846\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.5659 - accuracy: 0.6831 - val_loss: 1.5023 - val_accuracy: 0.6901\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.5380 - accuracy: 0.6852 - val_loss: 1.4679 - val_accuracy: 0.7048\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.5107 - accuracy: 0.6884 - val_loss: 1.4644 - val_accuracy: 0.7048\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4999 - accuracy: 0.6996 - val_loss: 1.4345 - val_accuracy: 0.7121\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4958 - accuracy: 0.7007 - val_loss: 1.4484 - val_accuracy: 0.7185\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4662 - accuracy: 0.7106 - val_loss: 1.4128 - val_accuracy: 0.7285\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4593 - accuracy: 0.7037 - val_loss: 1.4154 - val_accuracy: 0.7249\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4448 - accuracy: 0.7133 - val_loss: 1.4469 - val_accuracy: 0.7212\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4430 - accuracy: 0.7085 - val_loss: 1.3539 - val_accuracy: 0.7422\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.4052 - accuracy: 0.7229 - val_loss: 1.3823 - val_accuracy: 0.7121\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.3947 - accuracy: 0.7279 - val_loss: 1.3880 - val_accuracy: 0.7230\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 1.3908 - accuracy: 0.7243 - val_loss: 1.3346 - val_accuracy: 0.7404\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.3885 - accuracy: 0.7291 - val_loss: 1.3395 - val_accuracy: 0.7413\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.3863 - accuracy: 0.7414 - val_loss: 1.3841 - val_accuracy: 0.7358\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.3629 - accuracy: 0.7325 - val_loss: 1.3212 - val_accuracy: 0.7422\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.3307 - accuracy: 0.7460 - val_loss: 1.3212 - val_accuracy: 0.7468\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.3364 - accuracy: 0.7501 - val_loss: 1.3276 - val_accuracy: 0.7413\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.3502 - accuracy: 0.7391 - val_loss: 1.3278 - val_accuracy: 0.7514\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.3279 - accuracy: 0.7485 - val_loss: 1.3039 - val_accuracy: 0.7569\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.3158 - accuracy: 0.7524 - val_loss: 1.2945 - val_accuracy: 0.7477\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.3206 - accuracy: 0.7481 - val_loss: 1.3070 - val_accuracy: 0.7459\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.3125 - accuracy: 0.7494 - val_loss: 1.3176 - val_accuracy: 0.7532\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2948 - accuracy: 0.7540 - val_loss: 1.2885 - val_accuracy: 0.7669\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2741 - accuracy: 0.7657 - val_loss: 1.2861 - val_accuracy: 0.7532\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2602 - accuracy: 0.7721 - val_loss: 1.2832 - val_accuracy: 0.7541\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2668 - accuracy: 0.7666 - val_loss: 1.2848 - val_accuracy: 0.7550\n",
      "Epoch 53/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.2647 - accuracy: 0.7670 - val_loss: 1.2726 - val_accuracy: 0.7541\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2653 - accuracy: 0.7659 - val_loss: 1.2673 - val_accuracy: 0.7779\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2468 - accuracy: 0.7741 - val_loss: 1.2518 - val_accuracy: 0.7550\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.2577 - accuracy: 0.7673 - val_loss: 1.2648 - val_accuracy: 0.7687\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.2383 - accuracy: 0.7753 - val_loss: 1.2232 - val_accuracy: 0.7788\n",
      "Epoch 58/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2233 - accuracy: 0.7778 - val_loss: 1.2818 - val_accuracy: 0.7514\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2145 - accuracy: 0.7801 - val_loss: 1.2367 - val_accuracy: 0.7843\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1877 - accuracy: 0.7865 - val_loss: 1.2327 - val_accuracy: 0.7724\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.2192 - accuracy: 0.7778 - val_loss: 1.2301 - val_accuracy: 0.7678\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1774 - accuracy: 0.7917 - val_loss: 1.2138 - val_accuracy: 0.7925\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1759 - accuracy: 0.7904 - val_loss: 1.2418 - val_accuracy: 0.7724\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1764 - accuracy: 0.7952 - val_loss: 1.2192 - val_accuracy: 0.7861\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1651 - accuracy: 0.7942 - val_loss: 1.1951 - val_accuracy: 0.7861\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1678 - accuracy: 0.7940 - val_loss: 1.1824 - val_accuracy: 0.7834\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1469 - accuracy: 0.7922 - val_loss: 1.1960 - val_accuracy: 0.7879\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1466 - accuracy: 0.8009 - val_loss: 1.1896 - val_accuracy: 0.7852\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1402 - accuracy: 0.7970 - val_loss: 1.1940 - val_accuracy: 0.7916\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1340 - accuracy: 0.8036 - val_loss: 1.2002 - val_accuracy: 0.7925\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1183 - accuracy: 0.8089 - val_loss: 1.1801 - val_accuracy: 0.7870\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1195 - accuracy: 0.8109 - val_loss: 1.1954 - val_accuracy: 0.7824\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1137 - accuracy: 0.8052 - val_loss: 1.1575 - val_accuracy: 0.7934\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1296 - accuracy: 0.8061 - val_loss: 1.2116 - val_accuracy: 0.7834\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.1244 - accuracy: 0.8102 - val_loss: 1.1671 - val_accuracy: 0.7788\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1150 - accuracy: 0.8029 - val_loss: 1.2017 - val_accuracy: 0.7770\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0970 - accuracy: 0.8148 - val_loss: 1.1805 - val_accuracy: 0.7925\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1203 - accuracy: 0.8043 - val_loss: 1.1201 - val_accuracy: 0.8154\n",
      "Epoch 79/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0813 - accuracy: 0.8182 - val_loss: 1.1514 - val_accuracy: 0.8062\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0912 - accuracy: 0.8130 - val_loss: 1.1899 - val_accuracy: 0.7870\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0952 - accuracy: 0.8150 - val_loss: 1.1922 - val_accuracy: 0.7843\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.1053 - accuracy: 0.8086 - val_loss: 1.1818 - val_accuracy: 0.7980\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 1.1015 - accuracy: 0.8128 - val_loss: 1.1759 - val_accuracy: 0.7998\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0706 - accuracy: 0.8205 - val_loss: 1.1575 - val_accuracy: 0.8053\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0702 - accuracy: 0.8217 - val_loss: 1.1739 - val_accuracy: 0.7916\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0626 - accuracy: 0.8249 - val_loss: 1.1227 - val_accuracy: 0.8144\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0727 - accuracy: 0.8201 - val_loss: 1.1337 - val_accuracy: 0.8090\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0494 - accuracy: 0.8294 - val_loss: 1.1624 - val_accuracy: 0.8035\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0531 - accuracy: 0.8265 - val_loss: 1.1516 - val_accuracy: 0.7962\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0506 - accuracy: 0.8294 - val_loss: 1.1298 - val_accuracy: 0.7925\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0331 - accuracy: 0.8370 - val_loss: 1.1460 - val_accuracy: 0.8026\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0322 - accuracy: 0.8308 - val_loss: 1.1178 - val_accuracy: 0.8062\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0457 - accuracy: 0.8333 - val_loss: 1.1150 - val_accuracy: 0.8126\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0190 - accuracy: 0.8342 - val_loss: 1.1142 - val_accuracy: 0.8108\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0123 - accuracy: 0.8358 - val_loss: 1.1124 - val_accuracy: 0.8163\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0248 - accuracy: 0.8322 - val_loss: 1.1313 - val_accuracy: 0.8026\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0205 - accuracy: 0.8361 - val_loss: 1.1275 - val_accuracy: 0.8062\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0187 - accuracy: 0.8333 - val_loss: 1.1011 - val_accuracy: 0.8190\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0140 - accuracy: 0.8413 - val_loss: 1.1175 - val_accuracy: 0.8163\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9949 - accuracy: 0.8418 - val_loss: 1.1185 - val_accuracy: 0.8108\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0113 - accuracy: 0.8384 - val_loss: 1.0779 - val_accuracy: 0.8208\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.9785 - accuracy: 0.8489 - val_loss: 1.1152 - val_accuracy: 0.8062\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9863 - accuracy: 0.8420 - val_loss: 1.1147 - val_accuracy: 0.8062\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0203 - accuracy: 0.8340 - val_loss: 1.1209 - val_accuracy: 0.8071\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 1.0004 - accuracy: 0.8411 - val_loss: 1.0881 - val_accuracy: 0.8181\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9802 - accuracy: 0.8528 - val_loss: 1.1240 - val_accuracy: 0.8154\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9951 - accuracy: 0.8363 - val_loss: 1.0995 - val_accuracy: 0.8117\n",
      "Epoch 108/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9477 - accuracy: 0.8562 - val_loss: 1.1330 - val_accuracy: 0.8007\n",
      "Epoch 109/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9827 - accuracy: 0.8400 - val_loss: 1.0860 - val_accuracy: 0.8071\n",
      "Epoch 110/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9743 - accuracy: 0.8507 - val_loss: 1.1032 - val_accuracy: 0.8080\n",
      "Epoch 111/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9702 - accuracy: 0.8441 - val_loss: 1.1051 - val_accuracy: 0.8099\n",
      "Epoch 112/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9755 - accuracy: 0.8459 - val_loss: 1.1341 - val_accuracy: 0.8016\n",
      "Epoch 113/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9634 - accuracy: 0.8512 - val_loss: 1.1044 - val_accuracy: 0.8007\n",
      "Epoch 114/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9522 - accuracy: 0.8539 - val_loss: 1.0734 - val_accuracy: 0.8099\n",
      "Epoch 115/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9603 - accuracy: 0.8512 - val_loss: 1.0867 - val_accuracy: 0.8236\n",
      "Epoch 116/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9822 - accuracy: 0.8381 - val_loss: 1.1009 - val_accuracy: 0.8108\n",
      "Epoch 117/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9655 - accuracy: 0.8516 - val_loss: 1.0481 - val_accuracy: 0.8382\n",
      "Epoch 118/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9541 - accuracy: 0.8528 - val_loss: 1.0766 - val_accuracy: 0.8108\n",
      "Epoch 119/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9385 - accuracy: 0.8557 - val_loss: 1.0849 - val_accuracy: 0.8199\n",
      "Epoch 120/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9455 - accuracy: 0.8580 - val_loss: 1.0703 - val_accuracy: 0.8199\n",
      "Epoch 121/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9651 - accuracy: 0.8493 - val_loss: 1.1200 - val_accuracy: 0.7989\n",
      "Epoch 122/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9226 - accuracy: 0.8699 - val_loss: 1.0712 - val_accuracy: 0.8190\n",
      "Epoch 123/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9409 - accuracy: 0.8523 - val_loss: 1.0898 - val_accuracy: 0.8144\n",
      "Epoch 124/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9409 - accuracy: 0.8569 - val_loss: 1.0675 - val_accuracy: 0.8181\n",
      "Epoch 125/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9393 - accuracy: 0.8548 - val_loss: 1.0747 - val_accuracy: 0.8163\n",
      "Epoch 126/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9224 - accuracy: 0.8653 - val_loss: 1.0732 - val_accuracy: 0.8181\n",
      "Epoch 127/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.9323 - accuracy: 0.8555 - val_loss: 1.0731 - val_accuracy: 0.8218\n",
      "Epoch 128/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9318 - accuracy: 0.8571 - val_loss: 1.0604 - val_accuracy: 0.8236\n",
      "Epoch 129/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9340 - accuracy: 0.8564 - val_loss: 1.0762 - val_accuracy: 0.8218\n",
      "Epoch 130/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9144 - accuracy: 0.8637 - val_loss: 1.0544 - val_accuracy: 0.8218\n",
      "Epoch 131/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9401 - accuracy: 0.8555 - val_loss: 1.0316 - val_accuracy: 0.8272\n",
      "Epoch 132/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9306 - accuracy: 0.8615 - val_loss: 1.0544 - val_accuracy: 0.8364\n",
      "Epoch 133/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9291 - accuracy: 0.8585 - val_loss: 1.0449 - val_accuracy: 0.8309\n",
      "Epoch 134/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9362 - accuracy: 0.8564 - val_loss: 1.0748 - val_accuracy: 0.8154\n",
      "Epoch 135/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9417 - accuracy: 0.8537 - val_loss: 1.0565 - val_accuracy: 0.8236\n",
      "Epoch 136/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9300 - accuracy: 0.8612 - val_loss: 1.0494 - val_accuracy: 0.8373\n",
      "Epoch 137/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8973 - accuracy: 0.8736 - val_loss: 1.0570 - val_accuracy: 0.8282\n",
      "Epoch 138/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9140 - accuracy: 0.8667 - val_loss: 1.0585 - val_accuracy: 0.8300\n",
      "Epoch 139/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9153 - accuracy: 0.8610 - val_loss: 1.0687 - val_accuracy: 0.8199\n",
      "Epoch 140/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9052 - accuracy: 0.8658 - val_loss: 1.0638 - val_accuracy: 0.8236\n",
      "Epoch 141/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9066 - accuracy: 0.8578 - val_loss: 1.0694 - val_accuracy: 0.8199\n",
      "Epoch 142/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8953 - accuracy: 0.8715 - val_loss: 1.0934 - val_accuracy: 0.8117\n",
      "Epoch 143/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9217 - accuracy: 0.8596 - val_loss: 1.1001 - val_accuracy: 0.8199\n",
      "Epoch 144/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.9132 - accuracy: 0.8621 - val_loss: 1.0652 - val_accuracy: 0.8163\n",
      "Epoch 145/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8816 - accuracy: 0.8779 - val_loss: 1.0559 - val_accuracy: 0.8245\n",
      "Epoch 146/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8852 - accuracy: 0.8713 - val_loss: 1.0545 - val_accuracy: 0.8190\n",
      "Epoch 147/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8854 - accuracy: 0.8701 - val_loss: 1.0619 - val_accuracy: 0.8272\n",
      "Epoch 148/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8811 - accuracy: 0.8738 - val_loss: 1.0361 - val_accuracy: 0.8254\n",
      "Epoch 149/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8719 - accuracy: 0.8765 - val_loss: 1.0343 - val_accuracy: 0.8218\n",
      "Epoch 150/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.8723 - accuracy: 0.8727 - val_loss: 1.0371 - val_accuracy: 0.8346\n",
      "Epoch 151/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8907 - accuracy: 0.8651 - val_loss: 1.0417 - val_accuracy: 0.8062\n",
      "Epoch 152/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8731 - accuracy: 0.8736 - val_loss: 1.0340 - val_accuracy: 0.8263\n",
      "Epoch 153/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8883 - accuracy: 0.8653 - val_loss: 1.0522 - val_accuracy: 0.8291\n",
      "Epoch 154/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8614 - accuracy: 0.8825 - val_loss: 1.0595 - val_accuracy: 0.8199\n",
      "Epoch 155/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8842 - accuracy: 0.8637 - val_loss: 1.0841 - val_accuracy: 0.8181\n",
      "Epoch 156/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8636 - accuracy: 0.8800 - val_loss: 1.0408 - val_accuracy: 0.8291\n",
      "Epoch 157/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8681 - accuracy: 0.8743 - val_loss: 1.0523 - val_accuracy: 0.8218\n",
      "Epoch 158/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8402 - accuracy: 0.8896 - val_loss: 1.0625 - val_accuracy: 0.8154\n",
      "Epoch 159/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8542 - accuracy: 0.8855 - val_loss: 1.0086 - val_accuracy: 0.8400\n",
      "Epoch 160/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8373 - accuracy: 0.8857 - val_loss: 1.0504 - val_accuracy: 0.8199\n",
      "Epoch 161/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8536 - accuracy: 0.8807 - val_loss: 1.0283 - val_accuracy: 0.8336\n",
      "Epoch 162/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8623 - accuracy: 0.8811 - val_loss: 1.0748 - val_accuracy: 0.8172\n",
      "Epoch 163/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8681 - accuracy: 0.8747 - val_loss: 1.0602 - val_accuracy: 0.8172\n",
      "Epoch 164/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8589 - accuracy: 0.8804 - val_loss: 1.0650 - val_accuracy: 0.8236\n",
      "Epoch 165/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8595 - accuracy: 0.8802 - val_loss: 1.0485 - val_accuracy: 0.8208\n",
      "Epoch 166/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8276 - accuracy: 0.8884 - val_loss: 1.0511 - val_accuracy: 0.8245\n",
      "Epoch 167/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8491 - accuracy: 0.8781 - val_loss: 1.0178 - val_accuracy: 0.8428\n",
      "Epoch 168/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8516 - accuracy: 0.8747 - val_loss: 1.0411 - val_accuracy: 0.8227\n",
      "Epoch 169/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8671 - accuracy: 0.8816 - val_loss: 1.0467 - val_accuracy: 0.8190\n",
      "Epoch 170/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.8521 - accuracy: 0.8845 - val_loss: 1.0306 - val_accuracy: 0.8346\n",
      "Epoch 171/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.8529 - accuracy: 0.8729 - val_loss: 1.0462 - val_accuracy: 0.8245\n",
      "Epoch 172/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8451 - accuracy: 0.8841 - val_loss: 1.0391 - val_accuracy: 0.8245\n",
      "Epoch 173/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8284 - accuracy: 0.8912 - val_loss: 1.0106 - val_accuracy: 0.8327\n",
      "Epoch 174/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8226 - accuracy: 0.8900 - val_loss: 1.0049 - val_accuracy: 0.8336\n",
      "Epoch 175/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8197 - accuracy: 0.8877 - val_loss: 1.0253 - val_accuracy: 0.8218\n",
      "Epoch 176/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8445 - accuracy: 0.8797 - val_loss: 1.0471 - val_accuracy: 0.8272\n",
      "Epoch 177/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8374 - accuracy: 0.8875 - val_loss: 1.0438 - val_accuracy: 0.8291\n",
      "Epoch 178/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8336 - accuracy: 0.8845 - val_loss: 1.0225 - val_accuracy: 0.8263\n",
      "Epoch 179/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8382 - accuracy: 0.8850 - val_loss: 1.0651 - val_accuracy: 0.8135\n",
      "Epoch 180/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8395 - accuracy: 0.8779 - val_loss: 1.0455 - val_accuracy: 0.8391\n",
      "Epoch 181/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8301 - accuracy: 0.8875 - val_loss: 1.0219 - val_accuracy: 0.8410\n",
      "Epoch 182/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8197 - accuracy: 0.8884 - val_loss: 1.0099 - val_accuracy: 0.8336\n",
      "Epoch 183/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8096 - accuracy: 0.8903 - val_loss: 0.9845 - val_accuracy: 0.8547\n",
      "Epoch 184/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8155 - accuracy: 0.8829 - val_loss: 1.0403 - val_accuracy: 0.8272\n",
      "Epoch 185/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8364 - accuracy: 0.8752 - val_loss: 1.0396 - val_accuracy: 0.8236\n",
      "Epoch 186/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8353 - accuracy: 0.8811 - val_loss: 1.0287 - val_accuracy: 0.8254\n",
      "Epoch 187/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8348 - accuracy: 0.8839 - val_loss: 1.0189 - val_accuracy: 0.8291\n",
      "Epoch 188/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8273 - accuracy: 0.8832 - val_loss: 1.0347 - val_accuracy: 0.8172\n",
      "Epoch 189/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8198 - accuracy: 0.8893 - val_loss: 1.0422 - val_accuracy: 0.8245\n",
      "Epoch 190/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.8272 - accuracy: 0.8864 - val_loss: 1.0191 - val_accuracy: 0.8428\n",
      "Epoch 191/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8267 - accuracy: 0.8834 - val_loss: 1.0111 - val_accuracy: 0.8245\n",
      "Epoch 192/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8281 - accuracy: 0.8825 - val_loss: 1.0500 - val_accuracy: 0.8181\n",
      "Epoch 193/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8165 - accuracy: 0.8925 - val_loss: 1.0026 - val_accuracy: 0.8336\n",
      "Epoch 194/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8195 - accuracy: 0.8912 - val_loss: 1.0200 - val_accuracy: 0.8309\n",
      "Epoch 195/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8080 - accuracy: 0.8873 - val_loss: 1.0422 - val_accuracy: 0.8291\n",
      "Epoch 196/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8271 - accuracy: 0.8843 - val_loss: 1.0268 - val_accuracy: 0.8327\n",
      "Epoch 197/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8281 - accuracy: 0.8850 - val_loss: 1.0262 - val_accuracy: 0.8355\n",
      "Epoch 198/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8245 - accuracy: 0.8868 - val_loss: 1.0123 - val_accuracy: 0.8355\n",
      "Epoch 199/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7837 - accuracy: 0.8967 - val_loss: 1.0040 - val_accuracy: 0.8309\n",
      "Epoch 200/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8001 - accuracy: 0.8919 - val_loss: 0.9762 - val_accuracy: 0.8400\n",
      "Epoch 201/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8105 - accuracy: 0.8850 - val_loss: 1.0207 - val_accuracy: 0.8327\n",
      "Epoch 202/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7967 - accuracy: 0.8937 - val_loss: 1.0120 - val_accuracy: 0.8391\n",
      "Epoch 203/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7784 - accuracy: 0.8994 - val_loss: 1.0062 - val_accuracy: 0.8263\n",
      "Epoch 204/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7928 - accuracy: 0.8941 - val_loss: 0.9868 - val_accuracy: 0.8455\n",
      "Epoch 205/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7871 - accuracy: 0.8925 - val_loss: 1.0146 - val_accuracy: 0.8327\n",
      "Epoch 206/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7931 - accuracy: 0.8912 - val_loss: 0.9982 - val_accuracy: 0.8309\n",
      "Epoch 207/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7955 - accuracy: 0.8898 - val_loss: 0.9980 - val_accuracy: 0.8400\n",
      "Epoch 208/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7934 - accuracy: 0.8969 - val_loss: 1.0295 - val_accuracy: 0.8346\n",
      "Epoch 209/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7931 - accuracy: 0.8916 - val_loss: 0.9850 - val_accuracy: 0.8400\n",
      "Epoch 210/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7685 - accuracy: 0.9019 - val_loss: 0.9735 - val_accuracy: 0.8455\n",
      "Epoch 211/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7838 - accuracy: 0.8930 - val_loss: 0.9880 - val_accuracy: 0.8382\n",
      "Epoch 212/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7877 - accuracy: 0.8932 - val_loss: 1.0526 - val_accuracy: 0.8163\n",
      "Epoch 213/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7928 - accuracy: 0.8973 - val_loss: 0.9972 - val_accuracy: 0.8373\n",
      "Epoch 214/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7812 - accuracy: 0.8987 - val_loss: 1.0129 - val_accuracy: 0.8327\n",
      "Epoch 215/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7589 - accuracy: 0.9024 - val_loss: 0.9800 - val_accuracy: 0.8400\n",
      "Epoch 216/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7808 - accuracy: 0.8937 - val_loss: 1.0569 - val_accuracy: 0.8135\n",
      "Epoch 217/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8101 - accuracy: 0.8834 - val_loss: 0.9959 - val_accuracy: 0.8428\n",
      "Epoch 218/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7981 - accuracy: 0.8893 - val_loss: 1.0283 - val_accuracy: 0.8382\n",
      "Epoch 219/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8081 - accuracy: 0.8898 - val_loss: 0.9948 - val_accuracy: 0.8437\n",
      "Epoch 220/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7887 - accuracy: 0.8960 - val_loss: 1.0419 - val_accuracy: 0.8346\n",
      "Epoch 221/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7855 - accuracy: 0.8932 - val_loss: 1.0133 - val_accuracy: 0.8391\n",
      "Epoch 222/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7699 - accuracy: 0.9017 - val_loss: 0.9997 - val_accuracy: 0.8263\n",
      "Epoch 223/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7929 - accuracy: 0.8855 - val_loss: 0.9950 - val_accuracy: 0.8391\n",
      "Epoch 224/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7731 - accuracy: 0.9001 - val_loss: 1.0199 - val_accuracy: 0.8263\n",
      "Epoch 225/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7810 - accuracy: 0.8898 - val_loss: 1.0111 - val_accuracy: 0.8309\n",
      "Epoch 226/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7874 - accuracy: 0.8891 - val_loss: 1.0004 - val_accuracy: 0.8373\n",
      "Epoch 227/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7896 - accuracy: 0.8953 - val_loss: 1.0048 - val_accuracy: 0.8446\n",
      "Epoch 228/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7646 - accuracy: 0.9081 - val_loss: 0.9840 - val_accuracy: 0.8391\n",
      "Epoch 229/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7638 - accuracy: 0.9053 - val_loss: 0.9804 - val_accuracy: 0.8355\n",
      "Epoch 230/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7741 - accuracy: 0.8925 - val_loss: 1.0059 - val_accuracy: 0.8327\n",
      "Epoch 231/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7629 - accuracy: 0.9067 - val_loss: 0.9984 - val_accuracy: 0.8346\n",
      "Epoch 232/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7705 - accuracy: 0.8928 - val_loss: 1.0085 - val_accuracy: 0.8327\n",
      "Epoch 233/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7633 - accuracy: 0.8996 - val_loss: 0.9895 - val_accuracy: 0.8364\n",
      "Epoch 234/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7942 - accuracy: 0.8843 - val_loss: 1.0001 - val_accuracy: 0.8455\n",
      "Epoch 235/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7931 - accuracy: 0.8900 - val_loss: 1.0316 - val_accuracy: 0.8318\n",
      "Epoch 236/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7672 - accuracy: 0.9012 - val_loss: 0.9891 - val_accuracy: 0.8300\n",
      "Epoch 237/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7748 - accuracy: 0.8980 - val_loss: 0.9707 - val_accuracy: 0.8501\n",
      "Epoch 238/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7546 - accuracy: 0.9042 - val_loss: 1.0150 - val_accuracy: 0.8318\n",
      "Epoch 239/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7589 - accuracy: 0.8992 - val_loss: 1.0154 - val_accuracy: 0.8245\n",
      "Epoch 240/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7610 - accuracy: 0.9001 - val_loss: 1.0139 - val_accuracy: 0.8346\n",
      "Epoch 241/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7706 - accuracy: 0.8962 - val_loss: 1.0402 - val_accuracy: 0.8318\n",
      "Epoch 242/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7543 - accuracy: 0.9031 - val_loss: 1.0165 - val_accuracy: 0.8318\n",
      "Epoch 243/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7335 - accuracy: 0.9090 - val_loss: 0.9807 - val_accuracy: 0.8510\n",
      "Epoch 244/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7567 - accuracy: 0.9012 - val_loss: 0.9769 - val_accuracy: 0.8300\n",
      "Epoch 245/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7432 - accuracy: 0.9058 - val_loss: 1.0123 - val_accuracy: 0.8373\n",
      "Epoch 246/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7519 - accuracy: 0.9005 - val_loss: 0.9929 - val_accuracy: 0.8355\n",
      "Epoch 247/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7571 - accuracy: 0.8971 - val_loss: 0.9825 - val_accuracy: 0.8428\n",
      "Epoch 248/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7521 - accuracy: 0.9044 - val_loss: 0.9873 - val_accuracy: 0.8355\n",
      "Epoch 249/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7440 - accuracy: 0.9051 - val_loss: 0.9609 - val_accuracy: 0.8391\n",
      "Epoch 250/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7493 - accuracy: 0.9028 - val_loss: 0.9722 - val_accuracy: 0.8501\n",
      "Epoch 251/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7478 - accuracy: 0.9031 - val_loss: 0.9889 - val_accuracy: 0.8455\n",
      "Epoch 252/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7498 - accuracy: 0.9024 - val_loss: 0.9759 - val_accuracy: 0.8410\n",
      "Epoch 253/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7469 - accuracy: 0.9015 - val_loss: 0.9996 - val_accuracy: 0.8355\n",
      "Epoch 254/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7727 - accuracy: 0.8916 - val_loss: 1.0045 - val_accuracy: 0.8300\n",
      "Epoch 255/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7194 - accuracy: 0.9200 - val_loss: 0.9686 - val_accuracy: 0.8419\n",
      "Epoch 256/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7264 - accuracy: 0.9063 - val_loss: 0.9611 - val_accuracy: 0.8382\n",
      "Epoch 257/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7512 - accuracy: 0.8989 - val_loss: 0.9779 - val_accuracy: 0.8446\n",
      "Epoch 258/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7431 - accuracy: 0.9040 - val_loss: 0.9918 - val_accuracy: 0.8373\n",
      "Epoch 259/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7608 - accuracy: 0.8962 - val_loss: 1.0100 - val_accuracy: 0.8263\n",
      "Epoch 260/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7589 - accuracy: 0.9033 - val_loss: 0.9921 - val_accuracy: 0.8336\n",
      "Epoch 261/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7586 - accuracy: 0.9021 - val_loss: 0.9856 - val_accuracy: 0.8501\n",
      "Epoch 262/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7386 - accuracy: 0.9102 - val_loss: 0.9728 - val_accuracy: 0.8391\n",
      "Epoch 263/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7372 - accuracy: 0.9028 - val_loss: 0.9622 - val_accuracy: 0.8318\n",
      "Epoch 264/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7375 - accuracy: 0.9026 - val_loss: 0.9708 - val_accuracy: 0.8419\n",
      "Epoch 265/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7195 - accuracy: 0.9092 - val_loss: 0.9909 - val_accuracy: 0.8272\n",
      "Epoch 266/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7349 - accuracy: 0.9074 - val_loss: 0.9738 - val_accuracy: 0.8291\n",
      "Epoch 267/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7438 - accuracy: 0.9010 - val_loss: 0.9684 - val_accuracy: 0.8492\n",
      "Epoch 268/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7327 - accuracy: 0.9051 - val_loss: 0.9716 - val_accuracy: 0.8583\n",
      "Epoch 269/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7280 - accuracy: 0.9056 - val_loss: 0.9961 - val_accuracy: 0.8263\n",
      "Epoch 270/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7444 - accuracy: 0.9021 - val_loss: 0.9704 - val_accuracy: 0.8446\n",
      "Epoch 271/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7370 - accuracy: 0.9076 - val_loss: 0.9773 - val_accuracy: 0.8528\n",
      "Epoch 272/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7297 - accuracy: 0.9092 - val_loss: 0.9901 - val_accuracy: 0.8336\n",
      "Epoch 273/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7439 - accuracy: 0.9021 - val_loss: 1.0198 - val_accuracy: 0.8327\n",
      "Epoch 274/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7231 - accuracy: 0.9108 - val_loss: 0.9529 - val_accuracy: 0.8455\n",
      "Epoch 275/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7323 - accuracy: 0.9090 - val_loss: 1.0063 - val_accuracy: 0.8336\n",
      "Epoch 276/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7253 - accuracy: 0.9095 - val_loss: 0.9772 - val_accuracy: 0.8492\n",
      "Epoch 277/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7425 - accuracy: 0.9035 - val_loss: 0.9719 - val_accuracy: 0.8446\n",
      "Epoch 278/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7428 - accuracy: 0.9010 - val_loss: 0.9958 - val_accuracy: 0.8455\n",
      "Epoch 279/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7197 - accuracy: 0.9102 - val_loss: 1.0156 - val_accuracy: 0.8263\n",
      "Epoch 280/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7301 - accuracy: 0.9053 - val_loss: 1.0099 - val_accuracy: 0.8263\n",
      "Epoch 281/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7325 - accuracy: 0.9037 - val_loss: 1.0024 - val_accuracy: 0.8355\n",
      "Epoch 282/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7282 - accuracy: 0.9053 - val_loss: 0.9949 - val_accuracy: 0.8391\n",
      "Epoch 283/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7139 - accuracy: 0.9124 - val_loss: 0.9418 - val_accuracy: 0.8537\n",
      "Epoch 284/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7149 - accuracy: 0.9072 - val_loss: 1.0146 - val_accuracy: 0.8218\n",
      "Epoch 285/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7232 - accuracy: 0.9081 - val_loss: 0.9516 - val_accuracy: 0.8473\n",
      "Epoch 286/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7363 - accuracy: 0.9035 - val_loss: 0.9948 - val_accuracy: 0.8373\n",
      "Epoch 287/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7272 - accuracy: 0.9081 - val_loss: 1.0063 - val_accuracy: 0.8419\n",
      "Epoch 288/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7383 - accuracy: 0.9051 - val_loss: 0.9835 - val_accuracy: 0.8492\n",
      "Epoch 289/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7191 - accuracy: 0.9099 - val_loss: 0.9655 - val_accuracy: 0.8455\n",
      "Epoch 290/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7369 - accuracy: 0.9035 - val_loss: 1.0108 - val_accuracy: 0.8318\n",
      "Epoch 291/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7323 - accuracy: 0.9072 - val_loss: 0.9996 - val_accuracy: 0.8282\n",
      "Epoch 292/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7441 - accuracy: 0.9010 - val_loss: 0.9466 - val_accuracy: 0.8528\n",
      "Epoch 293/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7451 - accuracy: 0.9026 - val_loss: 0.9843 - val_accuracy: 0.8428\n",
      "Epoch 294/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7135 - accuracy: 0.9159 - val_loss: 0.9597 - val_accuracy: 0.8437\n",
      "Epoch 295/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7089 - accuracy: 0.9124 - val_loss: 0.9707 - val_accuracy: 0.8327\n",
      "Epoch 296/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7162 - accuracy: 0.9136 - val_loss: 0.9577 - val_accuracy: 0.8400\n",
      "Epoch 297/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7147 - accuracy: 0.9070 - val_loss: 0.9460 - val_accuracy: 0.8446\n",
      "Epoch 298/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7056 - accuracy: 0.9104 - val_loss: 0.9502 - val_accuracy: 0.8501\n",
      "Epoch 299/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7199 - accuracy: 0.9056 - val_loss: 0.9955 - val_accuracy: 0.8300\n",
      "Epoch 300/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7070 - accuracy: 0.9104 - val_loss: 0.9676 - val_accuracy: 0.8327\n",
      "Epoch 301/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7179 - accuracy: 0.9056 - val_loss: 0.9660 - val_accuracy: 0.8437\n",
      "Epoch 302/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7043 - accuracy: 0.9131 - val_loss: 0.9667 - val_accuracy: 0.8336\n",
      "Epoch 303/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6857 - accuracy: 0.9216 - val_loss: 0.9412 - val_accuracy: 0.8428\n",
      "Epoch 304/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6781 - accuracy: 0.9200 - val_loss: 0.9349 - val_accuracy: 0.8510\n",
      "Epoch 305/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6804 - accuracy: 0.9186 - val_loss: 0.9517 - val_accuracy: 0.8382\n",
      "Epoch 306/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6918 - accuracy: 0.9129 - val_loss: 0.9604 - val_accuracy: 0.8400\n",
      "Epoch 307/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7131 - accuracy: 0.9044 - val_loss: 0.9697 - val_accuracy: 0.8346\n",
      "Epoch 308/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7250 - accuracy: 0.9060 - val_loss: 1.0140 - val_accuracy: 0.8336\n",
      "Epoch 309/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7174 - accuracy: 0.9074 - val_loss: 1.0036 - val_accuracy: 0.8291\n",
      "Epoch 310/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6991 - accuracy: 0.9198 - val_loss: 0.9506 - val_accuracy: 0.8446\n",
      "Epoch 311/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6934 - accuracy: 0.9145 - val_loss: 0.9465 - val_accuracy: 0.8428\n",
      "Epoch 312/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6871 - accuracy: 0.9159 - val_loss: 0.9495 - val_accuracy: 0.8391\n",
      "Epoch 313/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7226 - accuracy: 0.8989 - val_loss: 0.9643 - val_accuracy: 0.8419\n",
      "Epoch 314/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7309 - accuracy: 0.9047 - val_loss: 0.9961 - val_accuracy: 0.8510\n",
      "Epoch 315/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7156 - accuracy: 0.9115 - val_loss: 0.9946 - val_accuracy: 0.8373\n",
      "Epoch 316/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7069 - accuracy: 0.9138 - val_loss: 0.9243 - val_accuracy: 0.8611\n",
      "Epoch 317/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6848 - accuracy: 0.9177 - val_loss: 0.9708 - val_accuracy: 0.8355\n",
      "Epoch 318/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7101 - accuracy: 0.9051 - val_loss: 0.9749 - val_accuracy: 0.8346\n",
      "Epoch 319/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7217 - accuracy: 0.9092 - val_loss: 0.9440 - val_accuracy: 0.8428\n",
      "Epoch 320/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7098 - accuracy: 0.9120 - val_loss: 0.9414 - val_accuracy: 0.8483\n",
      "Epoch 321/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7131 - accuracy: 0.9097 - val_loss: 0.9570 - val_accuracy: 0.8492\n",
      "Epoch 322/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7206 - accuracy: 0.9090 - val_loss: 0.9846 - val_accuracy: 0.8382\n",
      "Epoch 323/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7121 - accuracy: 0.9120 - val_loss: 0.9313 - val_accuracy: 0.8519\n",
      "Epoch 324/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7079 - accuracy: 0.9111 - val_loss: 0.9096 - val_accuracy: 0.8565\n",
      "Epoch 325/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6945 - accuracy: 0.9179 - val_loss: 0.9374 - val_accuracy: 0.8565\n",
      "Epoch 326/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6938 - accuracy: 0.9145 - val_loss: 0.9479 - val_accuracy: 0.8501\n",
      "Epoch 327/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6738 - accuracy: 0.9200 - val_loss: 0.9267 - val_accuracy: 0.8574\n",
      "Epoch 328/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.9168 - val_loss: 0.9634 - val_accuracy: 0.8336\n",
      "Epoch 329/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.9186 - val_loss: 0.9653 - val_accuracy: 0.8492\n",
      "Epoch 330/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6999 - accuracy: 0.9044 - val_loss: 0.9432 - val_accuracy: 0.8492\n",
      "Epoch 331/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7145 - accuracy: 0.9095 - val_loss: 1.0105 - val_accuracy: 0.8263\n",
      "Epoch 332/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6974 - accuracy: 0.9136 - val_loss: 0.9856 - val_accuracy: 0.8291\n",
      "Epoch 333/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6714 - accuracy: 0.9239 - val_loss: 0.9678 - val_accuracy: 0.8428\n",
      "Epoch 334/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6809 - accuracy: 0.9115 - val_loss: 0.9346 - val_accuracy: 0.8492\n",
      "Epoch 335/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6865 - accuracy: 0.9159 - val_loss: 0.9421 - val_accuracy: 0.8437\n",
      "Epoch 336/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7055 - accuracy: 0.9049 - val_loss: 1.0025 - val_accuracy: 0.8318\n",
      "Epoch 337/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7147 - accuracy: 0.9086 - val_loss: 0.9407 - val_accuracy: 0.8574\n",
      "Epoch 338/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7090 - accuracy: 0.9129 - val_loss: 1.0113 - val_accuracy: 0.8346\n",
      "Epoch 339/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7075 - accuracy: 0.9143 - val_loss: 0.9639 - val_accuracy: 0.8373\n",
      "Epoch 340/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6885 - accuracy: 0.9204 - val_loss: 0.9951 - val_accuracy: 0.8464\n",
      "Epoch 341/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7020 - accuracy: 0.9136 - val_loss: 0.9413 - val_accuracy: 0.8528\n",
      "Epoch 342/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.9134 - val_loss: 0.9882 - val_accuracy: 0.8391\n",
      "Epoch 343/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6858 - accuracy: 0.9211 - val_loss: 0.9677 - val_accuracy: 0.8437\n",
      "Epoch 344/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6711 - accuracy: 0.9211 - val_loss: 0.9658 - val_accuracy: 0.8419\n",
      "Epoch 345/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6646 - accuracy: 0.9214 - val_loss: 0.9359 - val_accuracy: 0.8355\n",
      "Epoch 346/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.9147 - val_loss: 0.9401 - val_accuracy: 0.8364\n",
      "Epoch 347/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6563 - accuracy: 0.9241 - val_loss: 0.9926 - val_accuracy: 0.8272\n",
      "Epoch 348/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6677 - accuracy: 0.9202 - val_loss: 0.9416 - val_accuracy: 0.8419\n",
      "Epoch 349/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6584 - accuracy: 0.9230 - val_loss: 0.9345 - val_accuracy: 0.8519\n",
      "Epoch 350/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6633 - accuracy: 0.9177 - val_loss: 0.9209 - val_accuracy: 0.8510\n",
      "Epoch 351/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6733 - accuracy: 0.9161 - val_loss: 0.9512 - val_accuracy: 0.8355\n",
      "Epoch 352/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7081 - accuracy: 0.9053 - val_loss: 0.9665 - val_accuracy: 0.8391\n",
      "Epoch 353/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7230 - accuracy: 0.9003 - val_loss: 1.0075 - val_accuracy: 0.8446\n",
      "Epoch 354/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7071 - accuracy: 0.9097 - val_loss: 0.9469 - val_accuracy: 0.8492\n",
      "Epoch 355/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6956 - accuracy: 0.9097 - val_loss: 0.9650 - val_accuracy: 0.8373\n",
      "Epoch 356/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7026 - accuracy: 0.9083 - val_loss: 0.9505 - val_accuracy: 0.8455\n",
      "Epoch 357/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6998 - accuracy: 0.9138 - val_loss: 0.9653 - val_accuracy: 0.8510\n",
      "Epoch 358/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6910 - accuracy: 0.9120 - val_loss: 1.0095 - val_accuracy: 0.8227\n",
      "Epoch 359/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6702 - accuracy: 0.9184 - val_loss: 0.9658 - val_accuracy: 0.8391\n",
      "Epoch 360/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6696 - accuracy: 0.9184 - val_loss: 0.9232 - val_accuracy: 0.8528\n",
      "Epoch 361/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6579 - accuracy: 0.9266 - val_loss: 0.9680 - val_accuracy: 0.8245\n",
      "Epoch 362/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6825 - accuracy: 0.9140 - val_loss: 0.9949 - val_accuracy: 0.8437\n",
      "Epoch 363/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7044 - accuracy: 0.9099 - val_loss: 0.9978 - val_accuracy: 0.8309\n",
      "Epoch 364/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7059 - accuracy: 0.9111 - val_loss: 0.9667 - val_accuracy: 0.8437\n",
      "Epoch 365/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6768 - accuracy: 0.9202 - val_loss: 0.9390 - val_accuracy: 0.8437\n",
      "Epoch 366/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6878 - accuracy: 0.9129 - val_loss: 0.9169 - val_accuracy: 0.8537\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6840 - accuracy: 0.9143 - val_loss: 0.9402 - val_accuracy: 0.8446\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6930 - accuracy: 0.9122 - val_loss: 0.9471 - val_accuracy: 0.8391\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6913 - accuracy: 0.9170 - val_loss: 0.9591 - val_accuracy: 0.8473\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7039 - accuracy: 0.9088 - val_loss: 0.9468 - val_accuracy: 0.8483\n",
      "Epoch 371/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6963 - accuracy: 0.9170 - val_loss: 0.9950 - val_accuracy: 0.8355\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7057 - accuracy: 0.9056 - val_loss: 0.9279 - val_accuracy: 0.8492\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6942 - accuracy: 0.9177 - val_loss: 0.9575 - val_accuracy: 0.8537\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6637 - accuracy: 0.9225 - val_loss: 0.9401 - val_accuracy: 0.8400\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6529 - accuracy: 0.9278 - val_loss: 0.9350 - val_accuracy: 0.8492\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6758 - accuracy: 0.9111 - val_loss: 0.9376 - val_accuracy: 0.8464\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6876 - accuracy: 0.9140 - val_loss: 0.9401 - val_accuracy: 0.8510\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.9168 - val_loss: 0.9148 - val_accuracy: 0.8638\n",
      "Epoch 379/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6735 - accuracy: 0.9150 - val_loss: 0.9186 - val_accuracy: 0.8501\n",
      "Epoch 380/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6571 - accuracy: 0.9252 - val_loss: 0.9227 - val_accuracy: 0.8419\n",
      "Epoch 381/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6473 - accuracy: 0.9282 - val_loss: 0.9533 - val_accuracy: 0.8510\n",
      "Epoch 382/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6623 - accuracy: 0.9147 - val_loss: 0.9576 - val_accuracy: 0.8355\n",
      "Epoch 383/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6791 - accuracy: 0.9140 - val_loss: 0.9571 - val_accuracy: 0.8528\n",
      "Epoch 384/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6729 - accuracy: 0.9143 - val_loss: 0.9278 - val_accuracy: 0.8537\n",
      "Epoch 385/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6720 - accuracy: 0.9156 - val_loss: 0.8735 - val_accuracy: 0.8711\n",
      "Epoch 386/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6512 - accuracy: 0.9186 - val_loss: 0.9188 - val_accuracy: 0.8501\n",
      "Epoch 387/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6494 - accuracy: 0.9259 - val_loss: 0.9177 - val_accuracy: 0.8419\n",
      "Epoch 388/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6664 - accuracy: 0.9106 - val_loss: 0.9143 - val_accuracy: 0.8510\n",
      "Epoch 389/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6583 - accuracy: 0.9227 - val_loss: 0.9443 - val_accuracy: 0.8373\n",
      "Epoch 390/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6592 - accuracy: 0.9232 - val_loss: 0.9225 - val_accuracy: 0.8629\n",
      "Epoch 391/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6582 - accuracy: 0.9207 - val_loss: 0.9301 - val_accuracy: 0.8528\n",
      "Epoch 392/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6601 - accuracy: 0.9195 - val_loss: 0.9341 - val_accuracy: 0.8583\n",
      "Epoch 393/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6619 - accuracy: 0.9200 - val_loss: 0.9752 - val_accuracy: 0.8437\n",
      "Epoch 394/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6991 - accuracy: 0.9047 - val_loss: 0.9338 - val_accuracy: 0.8510\n",
      "Epoch 395/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6773 - accuracy: 0.9234 - val_loss: 0.9463 - val_accuracy: 0.8510\n",
      "Epoch 396/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6829 - accuracy: 0.9166 - val_loss: 0.9770 - val_accuracy: 0.8437\n",
      "Epoch 397/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6703 - accuracy: 0.9232 - val_loss: 0.9594 - val_accuracy: 0.8428\n",
      "Epoch 398/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6568 - accuracy: 0.9175 - val_loss: 0.9045 - val_accuracy: 0.8665\n",
      "Epoch 399/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6571 - accuracy: 0.9202 - val_loss: 0.9289 - val_accuracy: 0.8574\n",
      "Epoch 400/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6612 - accuracy: 0.9177 - val_loss: 0.9413 - val_accuracy: 0.8419\n",
      "Epoch 401/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6573 - accuracy: 0.9257 - val_loss: 0.9260 - val_accuracy: 0.8547\n",
      "Epoch 402/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6697 - accuracy: 0.9156 - val_loss: 0.9260 - val_accuracy: 0.8455\n",
      "Epoch 403/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6640 - accuracy: 0.9168 - val_loss: 0.9539 - val_accuracy: 0.8464\n",
      "Epoch 404/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6509 - accuracy: 0.9230 - val_loss: 0.9356 - val_accuracy: 0.8501\n",
      "Epoch 405/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6732 - accuracy: 0.9090 - val_loss: 0.9221 - val_accuracy: 0.8565\n",
      "Epoch 406/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6934 - accuracy: 0.9095 - val_loss: 1.0118 - val_accuracy: 0.8318\n",
      "Epoch 407/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6653 - accuracy: 0.9214 - val_loss: 0.9422 - val_accuracy: 0.8446\n",
      "Epoch 408/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6909 - accuracy: 0.9090 - val_loss: 0.9525 - val_accuracy: 0.8428\n",
      "Epoch 409/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6959 - accuracy: 0.9115 - val_loss: 1.0147 - val_accuracy: 0.8291\n",
      "Epoch 410/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6817 - accuracy: 0.9161 - val_loss: 0.9574 - val_accuracy: 0.8547\n",
      "Epoch 411/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6667 - accuracy: 0.9246 - val_loss: 0.9769 - val_accuracy: 0.8400\n",
      "Epoch 412/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6657 - accuracy: 0.9177 - val_loss: 0.9137 - val_accuracy: 0.8638\n",
      "Epoch 413/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6640 - accuracy: 0.9227 - val_loss: 0.9386 - val_accuracy: 0.8446\n",
      "Epoch 414/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6477 - accuracy: 0.9264 - val_loss: 0.9537 - val_accuracy: 0.8428\n",
      "Epoch 415/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6320 - accuracy: 0.9330 - val_loss: 0.9368 - val_accuracy: 0.8464\n",
      "Epoch 416/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6766 - accuracy: 0.9099 - val_loss: 0.9226 - val_accuracy: 0.8446\n",
      "Epoch 417/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6721 - accuracy: 0.9150 - val_loss: 0.9767 - val_accuracy: 0.8355\n",
      "Epoch 418/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6798 - accuracy: 0.9186 - val_loss: 0.9802 - val_accuracy: 0.8346\n",
      "Epoch 419/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6774 - accuracy: 0.9172 - val_loss: 0.9893 - val_accuracy: 0.8446\n",
      "Epoch 420/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6861 - accuracy: 0.9120 - val_loss: 0.9498 - val_accuracy: 0.8611\n",
      "Epoch 421/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6833 - accuracy: 0.9152 - val_loss: 0.9535 - val_accuracy: 0.8455\n",
      "Epoch 422/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6733 - accuracy: 0.9223 - val_loss: 0.9712 - val_accuracy: 0.8428\n",
      "Epoch 423/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6690 - accuracy: 0.9202 - val_loss: 1.0042 - val_accuracy: 0.8364\n",
      "Epoch 424/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6909 - accuracy: 0.9159 - val_loss: 0.9839 - val_accuracy: 0.8346\n",
      "Epoch 425/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6904 - accuracy: 0.9108 - val_loss: 0.9838 - val_accuracy: 0.8501\n",
      "Epoch 426/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6882 - accuracy: 0.9143 - val_loss: 0.9484 - val_accuracy: 0.8574\n",
      "Epoch 427/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6839 - accuracy: 0.9159 - val_loss: 0.9259 - val_accuracy: 0.8556\n",
      "Epoch 428/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6707 - accuracy: 0.9170 - val_loss: 0.9514 - val_accuracy: 0.8547\n",
      "Epoch 429/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6792 - accuracy: 0.9097 - val_loss: 0.9643 - val_accuracy: 0.8437\n",
      "Epoch 430/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6675 - accuracy: 0.9211 - val_loss: 0.9636 - val_accuracy: 0.8510\n",
      "Epoch 431/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6574 - accuracy: 0.9239 - val_loss: 0.9372 - val_accuracy: 0.8601\n",
      "Epoch 432/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6541 - accuracy: 0.9204 - val_loss: 0.9591 - val_accuracy: 0.8446\n",
      "Epoch 433/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6619 - accuracy: 0.9170 - val_loss: 0.9228 - val_accuracy: 0.8611\n",
      "Epoch 434/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6564 - accuracy: 0.9218 - val_loss: 0.9518 - val_accuracy: 0.8501\n",
      "Epoch 435/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6363 - accuracy: 0.9234 - val_loss: 0.9045 - val_accuracy: 0.8583\n",
      "Epoch 436/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6533 - accuracy: 0.9220 - val_loss: 0.9213 - val_accuracy: 0.8501\n",
      "Epoch 437/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6457 - accuracy: 0.9252 - val_loss: 0.8743 - val_accuracy: 0.8592\n",
      "Epoch 438/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6255 - accuracy: 0.9310 - val_loss: 0.8991 - val_accuracy: 0.8537\n",
      "Epoch 439/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.9255 - val_loss: 0.9219 - val_accuracy: 0.8547\n",
      "Epoch 440/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.9216 - val_loss: 0.9416 - val_accuracy: 0.8638\n",
      "Epoch 441/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6516 - accuracy: 0.9248 - val_loss: 0.9707 - val_accuracy: 0.8428\n",
      "Epoch 442/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6481 - accuracy: 0.9172 - val_loss: 0.9708 - val_accuracy: 0.8327\n",
      "Epoch 443/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6638 - accuracy: 0.9186 - val_loss: 0.9812 - val_accuracy: 0.8364\n",
      "Epoch 444/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6717 - accuracy: 0.9163 - val_loss: 0.9502 - val_accuracy: 0.8556\n",
      "Epoch 445/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6929 - accuracy: 0.9113 - val_loss: 0.9891 - val_accuracy: 0.8400\n",
      "Epoch 446/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7046 - accuracy: 0.9090 - val_loss: 0.9721 - val_accuracy: 0.8373\n",
      "Epoch 447/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6844 - accuracy: 0.9152 - val_loss: 0.9505 - val_accuracy: 0.8464\n",
      "Epoch 448/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6636 - accuracy: 0.9257 - val_loss: 0.9775 - val_accuracy: 0.8419\n",
      "Epoch 449/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6491 - accuracy: 0.9241 - val_loss: 0.9158 - val_accuracy: 0.8510\n",
      "Epoch 450/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6467 - accuracy: 0.9220 - val_loss: 0.9365 - val_accuracy: 0.8464\n",
      "Epoch 451/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6330 - accuracy: 0.9246 - val_loss: 0.9100 - val_accuracy: 0.8528\n",
      "Epoch 452/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6365 - accuracy: 0.9271 - val_loss: 0.9360 - val_accuracy: 0.8437\n",
      "Epoch 453/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6626 - accuracy: 0.9140 - val_loss: 0.9127 - val_accuracy: 0.8601\n",
      "Epoch 454/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6198 - accuracy: 0.9362 - val_loss: 0.9260 - val_accuracy: 0.8437\n",
      "Epoch 455/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6239 - accuracy: 0.9271 - val_loss: 0.9196 - val_accuracy: 0.8528\n",
      "Epoch 456/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6541 - accuracy: 0.9154 - val_loss: 0.9220 - val_accuracy: 0.8464\n",
      "Epoch 457/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6493 - accuracy: 0.9182 - val_loss: 0.9597 - val_accuracy: 0.8492\n",
      "Epoch 458/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6554 - accuracy: 0.9186 - val_loss: 0.9283 - val_accuracy: 0.8492\n",
      "Epoch 459/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6662 - accuracy: 0.9182 - val_loss: 0.9336 - val_accuracy: 0.8601\n",
      "Epoch 460/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6846 - accuracy: 0.9161 - val_loss: 0.9713 - val_accuracy: 0.8400\n",
      "Epoch 461/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6730 - accuracy: 0.9223 - val_loss: 0.9529 - val_accuracy: 0.8446\n",
      "Epoch 462/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6541 - accuracy: 0.9225 - val_loss: 0.9445 - val_accuracy: 0.8483\n",
      "Epoch 463/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6462 - accuracy: 0.9220 - val_loss: 0.9127 - val_accuracy: 0.8583\n",
      "Epoch 464/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6401 - accuracy: 0.9218 - val_loss: 0.9252 - val_accuracy: 0.8473\n",
      "Epoch 465/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6539 - accuracy: 0.9223 - val_loss: 0.9386 - val_accuracy: 0.8547\n",
      "Epoch 466/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6509 - accuracy: 0.9236 - val_loss: 0.9452 - val_accuracy: 0.8410\n",
      "Epoch 467/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6411 - accuracy: 0.9298 - val_loss: 0.9306 - val_accuracy: 0.8574\n",
      "Epoch 468/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6530 - accuracy: 0.9218 - val_loss: 0.9331 - val_accuracy: 0.8483\n",
      "Epoch 469/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6415 - accuracy: 0.9234 - val_loss: 0.9299 - val_accuracy: 0.8592\n",
      "Epoch 470/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6482 - accuracy: 0.9195 - val_loss: 0.9302 - val_accuracy: 0.8537\n",
      "Epoch 471/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6650 - accuracy: 0.9182 - val_loss: 0.9366 - val_accuracy: 0.8592\n",
      "Epoch 472/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6619 - accuracy: 0.9186 - val_loss: 0.9163 - val_accuracy: 0.8528\n",
      "Epoch 473/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6457 - accuracy: 0.9271 - val_loss: 0.9695 - val_accuracy: 0.8455\n",
      "Epoch 474/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6661 - accuracy: 0.9124 - val_loss: 0.8952 - val_accuracy: 0.8702\n",
      "Epoch 475/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.9143 - val_loss: 0.9326 - val_accuracy: 0.8556\n",
      "Epoch 476/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6320 - accuracy: 0.9321 - val_loss: 0.9485 - val_accuracy: 0.8510\n",
      "Epoch 477/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6419 - accuracy: 0.9246 - val_loss: 0.9201 - val_accuracy: 0.8501\n",
      "Epoch 478/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6449 - accuracy: 0.9250 - val_loss: 0.9257 - val_accuracy: 0.8592\n",
      "Epoch 479/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6368 - accuracy: 0.9275 - val_loss: 0.9052 - val_accuracy: 0.8601\n",
      "Epoch 480/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6367 - accuracy: 0.9275 - val_loss: 0.9010 - val_accuracy: 0.8556\n",
      "Epoch 481/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6310 - accuracy: 0.9268 - val_loss: 0.9309 - val_accuracy: 0.8519\n",
      "Epoch 482/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6327 - accuracy: 0.9234 - val_loss: 0.9218 - val_accuracy: 0.8464\n",
      "Epoch 483/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6358 - accuracy: 0.9223 - val_loss: 0.9818 - val_accuracy: 0.8400\n",
      "Epoch 484/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6426 - accuracy: 0.9262 - val_loss: 0.9344 - val_accuracy: 0.8483\n",
      "Epoch 485/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6519 - accuracy: 0.9220 - val_loss: 0.9330 - val_accuracy: 0.8455\n",
      "Epoch 486/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6254 - accuracy: 0.9289 - val_loss: 0.9216 - val_accuracy: 0.8501\n",
      "Epoch 487/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6366 - accuracy: 0.9227 - val_loss: 0.9316 - val_accuracy: 0.8556\n",
      "Epoch 488/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6594 - accuracy: 0.9127 - val_loss: 1.0261 - val_accuracy: 0.8282\n",
      "Epoch 489/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6676 - accuracy: 0.9198 - val_loss: 0.9483 - val_accuracy: 0.8556\n",
      "Epoch 490/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6607 - accuracy: 0.9161 - val_loss: 0.9468 - val_accuracy: 0.8492\n",
      "Epoch 491/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6579 - accuracy: 0.9202 - val_loss: 0.9635 - val_accuracy: 0.8547\n",
      "Epoch 492/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6592 - accuracy: 0.9236 - val_loss: 0.9601 - val_accuracy: 0.8446\n",
      "Epoch 493/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6541 - accuracy: 0.9152 - val_loss: 0.9405 - val_accuracy: 0.8473\n",
      "Epoch 494/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6709 - accuracy: 0.9140 - val_loss: 0.9838 - val_accuracy: 0.8537\n",
      "Epoch 495/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6531 - accuracy: 0.9230 - val_loss: 0.9512 - val_accuracy: 0.8629\n",
      "Epoch 496/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6436 - accuracy: 0.9298 - val_loss: 0.9359 - val_accuracy: 0.8611\n",
      "Epoch 497/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6683 - accuracy: 0.9200 - val_loss: 0.9542 - val_accuracy: 0.8510\n",
      "Epoch 498/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6648 - accuracy: 0.9182 - val_loss: 0.9511 - val_accuracy: 0.8556\n",
      "Epoch 499/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6442 - accuracy: 0.9278 - val_loss: 0.9026 - val_accuracy: 0.8583\n",
      "Epoch 500/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6263 - accuracy: 0.9314 - val_loss: 0.9361 - val_accuracy: 0.8492\n",
      "Epoch 501/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6570 - accuracy: 0.9147 - val_loss: 0.9310 - val_accuracy: 0.8464\n",
      "Epoch 502/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6403 - accuracy: 0.9266 - val_loss: 0.9859 - val_accuracy: 0.8327\n",
      "Epoch 503/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6423 - accuracy: 0.9236 - val_loss: 0.9078 - val_accuracy: 0.8611\n",
      "Epoch 504/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6481 - accuracy: 0.9145 - val_loss: 0.9214 - val_accuracy: 0.8528\n",
      "Epoch 505/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6553 - accuracy: 0.9216 - val_loss: 0.9479 - val_accuracy: 0.8492\n",
      "Epoch 506/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6529 - accuracy: 0.9225 - val_loss: 0.9017 - val_accuracy: 0.8446\n",
      "Epoch 507/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6337 - accuracy: 0.9218 - val_loss: 0.9466 - val_accuracy: 0.8428\n",
      "Epoch 508/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.9294 - val_loss: 0.9172 - val_accuracy: 0.8547\n",
      "Epoch 509/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6298 - accuracy: 0.9243 - val_loss: 0.8996 - val_accuracy: 0.8519\n",
      "Epoch 510/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6277 - accuracy: 0.9250 - val_loss: 0.9394 - val_accuracy: 0.8455\n",
      "Epoch 511/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6215 - accuracy: 0.9332 - val_loss: 0.9577 - val_accuracy: 0.8346\n",
      "Epoch 512/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6404 - accuracy: 0.9243 - val_loss: 0.9495 - val_accuracy: 0.8565\n",
      "Epoch 513/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6434 - accuracy: 0.9225 - val_loss: 0.9583 - val_accuracy: 0.8583\n",
      "Epoch 514/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6461 - accuracy: 0.9209 - val_loss: 0.9351 - val_accuracy: 0.8519\n",
      "Epoch 515/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6442 - accuracy: 0.9264 - val_loss: 0.9595 - val_accuracy: 0.8464\n",
      "Epoch 516/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6456 - accuracy: 0.9271 - val_loss: 0.9017 - val_accuracy: 0.8702\n",
      "Epoch 517/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6474 - accuracy: 0.9239 - val_loss: 0.9462 - val_accuracy: 0.8528\n",
      "Epoch 518/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6290 - accuracy: 0.9282 - val_loss: 0.9008 - val_accuracy: 0.8565\n",
      "Epoch 519/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6317 - accuracy: 0.9255 - val_loss: 0.9256 - val_accuracy: 0.8455\n",
      "Epoch 520/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6281 - accuracy: 0.9257 - val_loss: 0.9187 - val_accuracy: 0.8556\n",
      "Epoch 521/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6225 - accuracy: 0.9314 - val_loss: 0.9371 - val_accuracy: 0.8400\n",
      "Epoch 522/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6168 - accuracy: 0.9268 - val_loss: 0.9090 - val_accuracy: 0.8510\n",
      "Epoch 523/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6163 - accuracy: 0.9280 - val_loss: 0.9406 - val_accuracy: 0.8464\n",
      "Epoch 524/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6402 - accuracy: 0.9198 - val_loss: 0.9418 - val_accuracy: 0.8483\n",
      "Epoch 525/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6412 - accuracy: 0.9234 - val_loss: 0.9298 - val_accuracy: 0.8537\n",
      "Epoch 526/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6642 - accuracy: 0.9147 - val_loss: 0.9126 - val_accuracy: 0.8592\n",
      "Epoch 527/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6545 - accuracy: 0.9227 - val_loss: 0.9864 - val_accuracy: 0.8327\n",
      "Epoch 528/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6694 - accuracy: 0.9143 - val_loss: 1.0159 - val_accuracy: 0.8355\n",
      "Epoch 529/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6683 - accuracy: 0.9218 - val_loss: 0.9563 - val_accuracy: 0.8601\n",
      "Epoch 530/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6476 - accuracy: 0.9296 - val_loss: 0.9608 - val_accuracy: 0.8410\n",
      "Epoch 531/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6405 - accuracy: 0.9307 - val_loss: 0.9551 - val_accuracy: 0.8455\n",
      "Epoch 532/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6378 - accuracy: 0.9214 - val_loss: 0.9536 - val_accuracy: 0.8455\n",
      "Epoch 533/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.9246 - val_loss: 0.9018 - val_accuracy: 0.8656\n",
      "Epoch 534/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6196 - accuracy: 0.9342 - val_loss: 0.9198 - val_accuracy: 0.8410\n",
      "Epoch 535/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6313 - accuracy: 0.9214 - val_loss: 0.9296 - val_accuracy: 0.8473\n",
      "Epoch 536/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6697 - accuracy: 0.9166 - val_loss: 0.9970 - val_accuracy: 0.8346\n",
      "Epoch 537/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6845 - accuracy: 0.9122 - val_loss: 0.9311 - val_accuracy: 0.8556\n",
      "Epoch 538/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6659 - accuracy: 0.9209 - val_loss: 0.9665 - val_accuracy: 0.8473\n",
      "Epoch 539/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6782 - accuracy: 0.9143 - val_loss: 0.9786 - val_accuracy: 0.8419\n",
      "Epoch 540/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6789 - accuracy: 0.9147 - val_loss: 0.9420 - val_accuracy: 0.8519\n",
      "Epoch 541/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6544 - accuracy: 0.9241 - val_loss: 0.9324 - val_accuracy: 0.8620\n",
      "Epoch 542/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6528 - accuracy: 0.9257 - val_loss: 0.9244 - val_accuracy: 0.8501\n",
      "Epoch 543/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6390 - accuracy: 0.9248 - val_loss: 0.9549 - val_accuracy: 0.8428\n",
      "Epoch 544/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6219 - accuracy: 0.9305 - val_loss: 0.8938 - val_accuracy: 0.8638\n",
      "Epoch 545/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6264 - accuracy: 0.9230 - val_loss: 0.9219 - val_accuracy: 0.8473\n",
      "Epoch 546/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6296 - accuracy: 0.9271 - val_loss: 0.9733 - val_accuracy: 0.8464\n",
      "Epoch 547/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6598 - accuracy: 0.9140 - val_loss: 0.9810 - val_accuracy: 0.8309\n",
      "Epoch 548/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6851 - accuracy: 0.9127 - val_loss: 0.9471 - val_accuracy: 0.8647\n",
      "Epoch 549/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6493 - accuracy: 0.9236 - val_loss: 0.9143 - val_accuracy: 0.8611\n",
      "Epoch 550/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6316 - accuracy: 0.9287 - val_loss: 0.9116 - val_accuracy: 0.8638\n",
      "Epoch 551/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6171 - accuracy: 0.9330 - val_loss: 0.9168 - val_accuracy: 0.8410\n",
      "Epoch 552/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6255 - accuracy: 0.9271 - val_loss: 0.8959 - val_accuracy: 0.8528\n",
      "Epoch 553/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6283 - accuracy: 0.9248 - val_loss: 0.8988 - val_accuracy: 0.8611\n",
      "Epoch 554/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6305 - accuracy: 0.9257 - val_loss: 0.8977 - val_accuracy: 0.8629\n",
      "Epoch 555/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6186 - accuracy: 0.9246 - val_loss: 0.9362 - val_accuracy: 0.8419\n",
      "Epoch 556/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6209 - accuracy: 0.9287 - val_loss: 0.9239 - val_accuracy: 0.8528\n",
      "Epoch 557/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6301 - accuracy: 0.9248 - val_loss: 0.8935 - val_accuracy: 0.8611\n",
      "Epoch 558/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6289 - accuracy: 0.9243 - val_loss: 0.8847 - val_accuracy: 0.8739\n",
      "Epoch 559/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6134 - accuracy: 0.9321 - val_loss: 0.9105 - val_accuracy: 0.8620\n",
      "Epoch 560/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6129 - accuracy: 0.9321 - val_loss: 0.9161 - val_accuracy: 0.8483\n",
      "Epoch 561/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6287 - accuracy: 0.9223 - val_loss: 0.9372 - val_accuracy: 0.8547\n",
      "Epoch 562/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6298 - accuracy: 0.9241 - val_loss: 0.9589 - val_accuracy: 0.8382\n",
      "Epoch 563/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6502 - accuracy: 0.9188 - val_loss: 0.9154 - val_accuracy: 0.8537\n",
      "Epoch 564/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6454 - accuracy: 0.9243 - val_loss: 0.9235 - val_accuracy: 0.8556\n",
      "Epoch 565/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6549 - accuracy: 0.9234 - val_loss: 0.8875 - val_accuracy: 0.8620\n",
      "Epoch 566/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6149 - accuracy: 0.9316 - val_loss: 0.8879 - val_accuracy: 0.8693\n",
      "Epoch 567/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6173 - accuracy: 0.9323 - val_loss: 0.9463 - val_accuracy: 0.8419\n",
      "Epoch 568/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6183 - accuracy: 0.9255 - val_loss: 0.9645 - val_accuracy: 0.8473\n",
      "Epoch 569/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6079 - accuracy: 0.9332 - val_loss: 0.9135 - val_accuracy: 0.8574\n",
      "Epoch 570/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6268 - accuracy: 0.9209 - val_loss: 0.9396 - val_accuracy: 0.8437\n",
      "Epoch 571/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6257 - accuracy: 0.9264 - val_loss: 0.8955 - val_accuracy: 0.8647\n",
      "Epoch 572/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6222 - accuracy: 0.9252 - val_loss: 0.9308 - val_accuracy: 0.8510\n",
      "Epoch 573/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6299 - accuracy: 0.9220 - val_loss: 0.9645 - val_accuracy: 0.8492\n",
      "Epoch 574/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6494 - accuracy: 0.9227 - val_loss: 0.9079 - val_accuracy: 0.8638\n",
      "Epoch 575/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6319 - accuracy: 0.9248 - val_loss: 0.9109 - val_accuracy: 0.8519\n",
      "Epoch 576/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6306 - accuracy: 0.9287 - val_loss: 0.9196 - val_accuracy: 0.8528\n",
      "Epoch 577/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6381 - accuracy: 0.9225 - val_loss: 0.9537 - val_accuracy: 0.8565\n",
      "Epoch 578/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6234 - accuracy: 0.9291 - val_loss: 0.9138 - val_accuracy: 0.8647\n",
      "Epoch 579/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6271 - accuracy: 0.9268 - val_loss: 0.9022 - val_accuracy: 0.8592\n",
      "Epoch 580/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6325 - accuracy: 0.9239 - val_loss: 0.9090 - val_accuracy: 0.8620\n",
      "Epoch 581/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6405 - accuracy: 0.9211 - val_loss: 0.9552 - val_accuracy: 0.8410\n",
      "Epoch 582/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6571 - accuracy: 0.9147 - val_loss: 0.9331 - val_accuracy: 0.8519\n",
      "Epoch 583/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6278 - accuracy: 0.9289 - val_loss: 0.9283 - val_accuracy: 0.8537\n",
      "Epoch 584/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6246 - accuracy: 0.9273 - val_loss: 0.9073 - val_accuracy: 0.8611\n",
      "Epoch 585/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6322 - accuracy: 0.9250 - val_loss: 0.8831 - val_accuracy: 0.8629\n",
      "Epoch 586/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6230 - accuracy: 0.9278 - val_loss: 0.9220 - val_accuracy: 0.8492\n",
      "Epoch 587/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6236 - accuracy: 0.9282 - val_loss: 0.9090 - val_accuracy: 0.8556\n",
      "Epoch 588/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6386 - accuracy: 0.9232 - val_loss: 0.9609 - val_accuracy: 0.8437\n",
      "Epoch 589/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6504 - accuracy: 0.9207 - val_loss: 0.8999 - val_accuracy: 0.8601\n",
      "Epoch 590/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6489 - accuracy: 0.9230 - val_loss: 0.9125 - val_accuracy: 0.8547\n",
      "Epoch 591/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6336 - accuracy: 0.9280 - val_loss: 0.9559 - val_accuracy: 0.8382\n",
      "Epoch 592/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6279 - accuracy: 0.9250 - val_loss: 0.9143 - val_accuracy: 0.8556\n",
      "Epoch 593/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6356 - accuracy: 0.9214 - val_loss: 0.9142 - val_accuracy: 0.8638\n",
      "Epoch 594/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6529 - accuracy: 0.9202 - val_loss: 0.9166 - val_accuracy: 0.8675\n",
      "Epoch 595/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6280 - accuracy: 0.9314 - val_loss: 0.9022 - val_accuracy: 0.8611\n",
      "Epoch 596/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6314 - accuracy: 0.9278 - val_loss: 0.8823 - val_accuracy: 0.8629\n",
      "Epoch 597/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6017 - accuracy: 0.9371 - val_loss: 0.9193 - val_accuracy: 0.8537\n",
      "Epoch 598/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6073 - accuracy: 0.9335 - val_loss: 0.9422 - val_accuracy: 0.8473\n",
      "Epoch 599/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6161 - accuracy: 0.9275 - val_loss: 0.8924 - val_accuracy: 0.8601\n",
      "Epoch 600/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6171 - accuracy: 0.9278 - val_loss: 0.8930 - val_accuracy: 0.8638\n",
      "Epoch 601/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6144 - accuracy: 0.9321 - val_loss: 0.8992 - val_accuracy: 0.8611\n",
      "Epoch 602/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6159 - accuracy: 0.9312 - val_loss: 0.9230 - val_accuracy: 0.8464\n",
      "Epoch 603/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6099 - accuracy: 0.9291 - val_loss: 0.9148 - val_accuracy: 0.8675\n",
      "Epoch 604/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6148 - accuracy: 0.9291 - val_loss: 0.9447 - val_accuracy: 0.8419\n",
      "Epoch 605/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6468 - accuracy: 0.9175 - val_loss: 0.9351 - val_accuracy: 0.8483\n",
      "Epoch 606/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6141 - accuracy: 0.9316 - val_loss: 0.9440 - val_accuracy: 0.8464\n",
      "Epoch 607/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6219 - accuracy: 0.9257 - val_loss: 0.9691 - val_accuracy: 0.8291\n",
      "Epoch 608/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6243 - accuracy: 0.9316 - val_loss: 0.8806 - val_accuracy: 0.8693\n",
      "Epoch 609/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6159 - accuracy: 0.9296 - val_loss: 0.9081 - val_accuracy: 0.8528\n",
      "Epoch 610/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6034 - accuracy: 0.9307 - val_loss: 0.9483 - val_accuracy: 0.8455\n",
      "Epoch 611/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6030 - accuracy: 0.9300 - val_loss: 0.8897 - val_accuracy: 0.8629\n",
      "Epoch 612/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5949 - accuracy: 0.9348 - val_loss: 0.8886 - val_accuracy: 0.8537\n",
      "Epoch 613/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5882 - accuracy: 0.9358 - val_loss: 0.8951 - val_accuracy: 0.8611\n",
      "Epoch 614/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6000 - accuracy: 0.9273 - val_loss: 0.9290 - val_accuracy: 0.8419\n",
      "Epoch 615/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6217 - accuracy: 0.9250 - val_loss: 0.9250 - val_accuracy: 0.8355\n",
      "Epoch 616/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6160 - accuracy: 0.9271 - val_loss: 0.8993 - val_accuracy: 0.8556\n",
      "Epoch 617/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6300 - accuracy: 0.9246 - val_loss: 0.9553 - val_accuracy: 0.8428\n",
      "Epoch 618/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6337 - accuracy: 0.9264 - val_loss: 0.9323 - val_accuracy: 0.8519\n",
      "Epoch 619/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6475 - accuracy: 0.9188 - val_loss: 0.9566 - val_accuracy: 0.8537\n",
      "Epoch 620/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6364 - accuracy: 0.9271 - val_loss: 0.9505 - val_accuracy: 0.8473\n",
      "Epoch 621/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6357 - accuracy: 0.9230 - val_loss: 0.9056 - val_accuracy: 0.8647\n",
      "Epoch 622/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6097 - accuracy: 0.9360 - val_loss: 0.9140 - val_accuracy: 0.8473\n",
      "Epoch 623/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6274 - accuracy: 0.9246 - val_loss: 0.8818 - val_accuracy: 0.8620\n",
      "Epoch 624/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6370 - accuracy: 0.9266 - val_loss: 0.9198 - val_accuracy: 0.8483\n",
      "Epoch 625/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6221 - accuracy: 0.9323 - val_loss: 0.9472 - val_accuracy: 0.8464\n",
      "Epoch 626/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6329 - accuracy: 0.9230 - val_loss: 0.9359 - val_accuracy: 0.8592\n",
      "Epoch 627/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6442 - accuracy: 0.9250 - val_loss: 0.8828 - val_accuracy: 0.8556\n",
      "Epoch 628/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6126 - accuracy: 0.9298 - val_loss: 0.9084 - val_accuracy: 0.8455\n",
      "Epoch 629/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5974 - accuracy: 0.9362 - val_loss: 0.9053 - val_accuracy: 0.8592\n",
      "Epoch 630/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6053 - accuracy: 0.9300 - val_loss: 0.9118 - val_accuracy: 0.8492\n",
      "Epoch 631/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6113 - accuracy: 0.9271 - val_loss: 0.9142 - val_accuracy: 0.8501\n",
      "Epoch 632/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6167 - accuracy: 0.9259 - val_loss: 0.9106 - val_accuracy: 0.8547\n",
      "Epoch 633/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6325 - accuracy: 0.9211 - val_loss: 0.8887 - val_accuracy: 0.8647\n",
      "Epoch 634/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6252 - accuracy: 0.9280 - val_loss: 0.9515 - val_accuracy: 0.8501\n",
      "Epoch 635/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6222 - accuracy: 0.9287 - val_loss: 0.8935 - val_accuracy: 0.8629\n",
      "Epoch 636/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6403 - accuracy: 0.9211 - val_loss: 0.9045 - val_accuracy: 0.8519\n",
      "Epoch 637/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6327 - accuracy: 0.9268 - val_loss: 0.9103 - val_accuracy: 0.8583\n",
      "Epoch 638/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.9369 - val_loss: 0.9265 - val_accuracy: 0.8364\n",
      "Epoch 639/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5903 - accuracy: 0.9360 - val_loss: 0.8856 - val_accuracy: 0.8583\n",
      "Epoch 640/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6171 - accuracy: 0.9218 - val_loss: 0.9268 - val_accuracy: 0.8528\n",
      "Epoch 641/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6062 - accuracy: 0.9323 - val_loss: 0.8826 - val_accuracy: 0.8656\n",
      "Epoch 642/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6126 - accuracy: 0.9243 - val_loss: 0.9337 - val_accuracy: 0.8547\n",
      "Epoch 643/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6100 - accuracy: 0.9328 - val_loss: 0.9276 - val_accuracy: 0.8391\n",
      "Epoch 644/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6153 - accuracy: 0.9310 - val_loss: 0.8862 - val_accuracy: 0.8675\n",
      "Epoch 645/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6344 - accuracy: 0.9227 - val_loss: 0.9302 - val_accuracy: 0.8556\n",
      "Epoch 646/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6373 - accuracy: 0.9259 - val_loss: 0.9483 - val_accuracy: 0.8428\n",
      "Epoch 647/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6338 - accuracy: 0.9291 - val_loss: 0.9262 - val_accuracy: 0.8537\n",
      "Epoch 648/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6122 - accuracy: 0.9321 - val_loss: 0.9796 - val_accuracy: 0.8510\n",
      "Epoch 649/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6145 - accuracy: 0.9255 - val_loss: 0.9234 - val_accuracy: 0.8528\n",
      "Epoch 650/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6267 - accuracy: 0.9248 - val_loss: 0.9087 - val_accuracy: 0.8547\n",
      "Epoch 651/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6277 - accuracy: 0.9239 - val_loss: 0.9533 - val_accuracy: 0.8428\n",
      "Epoch 652/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6479 - accuracy: 0.9209 - val_loss: 0.9561 - val_accuracy: 0.8547\n",
      "Epoch 653/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6194 - accuracy: 0.9316 - val_loss: 0.9472 - val_accuracy: 0.8510\n",
      "Epoch 654/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6315 - accuracy: 0.9284 - val_loss: 0.9750 - val_accuracy: 0.8391\n",
      "Epoch 655/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6418 - accuracy: 0.9200 - val_loss: 0.9522 - val_accuracy: 0.8428\n",
      "Epoch 656/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6273 - accuracy: 0.9312 - val_loss: 0.9737 - val_accuracy: 0.8346\n",
      "Epoch 657/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6238 - accuracy: 0.9287 - val_loss: 0.9317 - val_accuracy: 0.8601\n",
      "Epoch 658/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6102 - accuracy: 0.9307 - val_loss: 0.9182 - val_accuracy: 0.8519\n",
      "Epoch 659/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6206 - accuracy: 0.9271 - val_loss: 0.9068 - val_accuracy: 0.8592\n",
      "Epoch 660/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6208 - accuracy: 0.9250 - val_loss: 0.9584 - val_accuracy: 0.8364\n",
      "Epoch 661/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6406 - accuracy: 0.9243 - val_loss: 0.9610 - val_accuracy: 0.8437\n",
      "Epoch 662/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6410 - accuracy: 0.9227 - val_loss: 0.9373 - val_accuracy: 0.8537\n",
      "Epoch 663/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6301 - accuracy: 0.9284 - val_loss: 0.9619 - val_accuracy: 0.8574\n",
      "Epoch 664/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6272 - accuracy: 0.9307 - val_loss: 0.9545 - val_accuracy: 0.8391\n",
      "Epoch 665/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6303 - accuracy: 0.9275 - val_loss: 0.9274 - val_accuracy: 0.8528\n",
      "Epoch 666/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6316 - accuracy: 0.9273 - val_loss: 0.9418 - val_accuracy: 0.8565\n",
      "Epoch 667/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6261 - accuracy: 0.9255 - val_loss: 0.9618 - val_accuracy: 0.8519\n",
      "Epoch 668/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6351 - accuracy: 0.9284 - val_loss: 0.9393 - val_accuracy: 0.8528\n",
      "Epoch 669/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6176 - accuracy: 0.9326 - val_loss: 0.9665 - val_accuracy: 0.8492\n",
      "Epoch 670/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6301 - accuracy: 0.9236 - val_loss: 0.9189 - val_accuracy: 0.8601\n",
      "Epoch 671/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6231 - accuracy: 0.9298 - val_loss: 0.8723 - val_accuracy: 0.8675\n",
      "Epoch 672/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6236 - accuracy: 0.9287 - val_loss: 0.9209 - val_accuracy: 0.8665\n",
      "Epoch 673/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6312 - accuracy: 0.9262 - val_loss: 0.9468 - val_accuracy: 0.8473\n",
      "Epoch 674/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6360 - accuracy: 0.9252 - val_loss: 0.9235 - val_accuracy: 0.8611\n",
      "Epoch 675/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6290 - accuracy: 0.9287 - val_loss: 0.9078 - val_accuracy: 0.8592\n",
      "Epoch 676/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6231 - accuracy: 0.9257 - val_loss: 0.8943 - val_accuracy: 0.8629\n",
      "Epoch 677/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5906 - accuracy: 0.9378 - val_loss: 0.9198 - val_accuracy: 0.8510\n",
      "Epoch 678/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5887 - accuracy: 0.9339 - val_loss: 0.8787 - val_accuracy: 0.8739\n",
      "Epoch 679/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6053 - accuracy: 0.9271 - val_loss: 0.9315 - val_accuracy: 0.8501\n",
      "Epoch 680/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6284 - accuracy: 0.9232 - val_loss: 0.9092 - val_accuracy: 0.8547\n",
      "Epoch 681/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6344 - accuracy: 0.9259 - val_loss: 0.9228 - val_accuracy: 0.8501\n",
      "Epoch 682/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6303 - accuracy: 0.9252 - val_loss: 0.9314 - val_accuracy: 0.8510\n",
      "Epoch 683/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6311 - accuracy: 0.9198 - val_loss: 0.9194 - val_accuracy: 0.8547\n",
      "Epoch 684/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6195 - accuracy: 0.9312 - val_loss: 0.9496 - val_accuracy: 0.8410\n",
      "Epoch 685/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6366 - accuracy: 0.9191 - val_loss: 0.9646 - val_accuracy: 0.8437\n",
      "Epoch 686/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6415 - accuracy: 0.9268 - val_loss: 0.9491 - val_accuracy: 0.8464\n",
      "Epoch 687/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6054 - accuracy: 0.9339 - val_loss: 0.9641 - val_accuracy: 0.8419\n",
      "Epoch 688/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6075 - accuracy: 0.9284 - val_loss: 0.8876 - val_accuracy: 0.8592\n",
      "Epoch 689/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6112 - accuracy: 0.9326 - val_loss: 0.9062 - val_accuracy: 0.8574\n",
      "Epoch 690/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5952 - accuracy: 0.9282 - val_loss: 0.9098 - val_accuracy: 0.8537\n",
      "Epoch 691/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6075 - accuracy: 0.9284 - val_loss: 0.9039 - val_accuracy: 0.8574\n",
      "Epoch 692/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6044 - accuracy: 0.9374 - val_loss: 0.9102 - val_accuracy: 0.8537\n",
      "Epoch 693/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6284 - accuracy: 0.9255 - val_loss: 0.9443 - val_accuracy: 0.8437\n",
      "Epoch 694/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6370 - accuracy: 0.9230 - val_loss: 0.9951 - val_accuracy: 0.8272\n",
      "Epoch 695/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6347 - accuracy: 0.9255 - val_loss: 0.9077 - val_accuracy: 0.8592\n",
      "Epoch 696/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6265 - accuracy: 0.9234 - val_loss: 0.9217 - val_accuracy: 0.8519\n",
      "Epoch 697/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6161 - accuracy: 0.9316 - val_loss: 0.9193 - val_accuracy: 0.8592\n",
      "Epoch 698/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6243 - accuracy: 0.9271 - val_loss: 0.9273 - val_accuracy: 0.8556\n",
      "Epoch 699/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6116 - accuracy: 0.9296 - val_loss: 0.9004 - val_accuracy: 0.8656\n",
      "Epoch 700/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6174 - accuracy: 0.9278 - val_loss: 0.8796 - val_accuracy: 0.8711\n",
      "Epoch 701/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6254 - accuracy: 0.9248 - val_loss: 0.9088 - val_accuracy: 0.8483\n",
      "Epoch 702/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6244 - accuracy: 0.9225 - val_loss: 0.9090 - val_accuracy: 0.8537\n",
      "Epoch 703/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6206 - accuracy: 0.9282 - val_loss: 0.9680 - val_accuracy: 0.8391\n",
      "Epoch 704/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6400 - accuracy: 0.9214 - val_loss: 0.9071 - val_accuracy: 0.8464\n",
      "Epoch 705/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6583 - accuracy: 0.9175 - val_loss: 0.9588 - val_accuracy: 0.8574\n",
      "Epoch 706/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6432 - accuracy: 0.9262 - val_loss: 1.0051 - val_accuracy: 0.8282\n",
      "Epoch 707/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6431 - accuracy: 0.9227 - val_loss: 0.9312 - val_accuracy: 0.8519\n",
      "Epoch 708/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6339 - accuracy: 0.9232 - val_loss: 0.9169 - val_accuracy: 0.8611\n",
      "Epoch 709/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6317 - accuracy: 0.9246 - val_loss: 0.8983 - val_accuracy: 0.8537\n",
      "Epoch 710/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6170 - accuracy: 0.9351 - val_loss: 0.9101 - val_accuracy: 0.8620\n",
      "Epoch 711/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6114 - accuracy: 0.9319 - val_loss: 0.8899 - val_accuracy: 0.8601\n",
      "Epoch 712/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6106 - accuracy: 0.9337 - val_loss: 0.9357 - val_accuracy: 0.8483\n",
      "Epoch 713/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6175 - accuracy: 0.9273 - val_loss: 0.8906 - val_accuracy: 0.8711\n",
      "Epoch 714/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5910 - accuracy: 0.9383 - val_loss: 0.8985 - val_accuracy: 0.8675\n",
      "Epoch 715/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6077 - accuracy: 0.9257 - val_loss: 0.9020 - val_accuracy: 0.8574\n",
      "Epoch 716/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6062 - accuracy: 0.9316 - val_loss: 0.9031 - val_accuracy: 0.8583\n",
      "Epoch 717/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6185 - accuracy: 0.9266 - val_loss: 0.9144 - val_accuracy: 0.8455\n",
      "Epoch 718/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6195 - accuracy: 0.9266 - val_loss: 0.9529 - val_accuracy: 0.8565\n",
      "Epoch 719/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6001 - accuracy: 0.9342 - val_loss: 0.9146 - val_accuracy: 0.8638\n",
      "Epoch 720/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6052 - accuracy: 0.9296 - val_loss: 0.9458 - val_accuracy: 0.8473\n",
      "Epoch 721/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6200 - accuracy: 0.9300 - val_loss: 0.9024 - val_accuracy: 0.8620\n",
      "Epoch 722/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5913 - accuracy: 0.9387 - val_loss: 0.9038 - val_accuracy: 0.8629\n",
      "Epoch 723/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5836 - accuracy: 0.9374 - val_loss: 0.9071 - val_accuracy: 0.8464\n",
      "Epoch 724/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5982 - accuracy: 0.9312 - val_loss: 0.9186 - val_accuracy: 0.8537\n",
      "Epoch 725/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6076 - accuracy: 0.9280 - val_loss: 0.9282 - val_accuracy: 0.8410\n",
      "Epoch 726/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6110 - accuracy: 0.9264 - val_loss: 0.9287 - val_accuracy: 0.8510\n",
      "Epoch 727/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5964 - accuracy: 0.9385 - val_loss: 0.9177 - val_accuracy: 0.8547\n",
      "Epoch 728/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5985 - accuracy: 0.9319 - val_loss: 0.9028 - val_accuracy: 0.8519\n",
      "Epoch 729/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6183 - accuracy: 0.9273 - val_loss: 0.8731 - val_accuracy: 0.8611\n",
      "Epoch 730/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6257 - accuracy: 0.9278 - val_loss: 0.8942 - val_accuracy: 0.8537\n",
      "Epoch 731/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6255 - accuracy: 0.9291 - val_loss: 0.9494 - val_accuracy: 0.8519\n",
      "Epoch 732/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6160 - accuracy: 0.9280 - val_loss: 0.9664 - val_accuracy: 0.8318\n",
      "Epoch 733/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6195 - accuracy: 0.9303 - val_loss: 0.8963 - val_accuracy: 0.8601\n",
      "Epoch 734/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6115 - accuracy: 0.9284 - val_loss: 0.9461 - val_accuracy: 0.8510\n",
      "Epoch 735/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6113 - accuracy: 0.9321 - val_loss: 0.9159 - val_accuracy: 0.8665\n",
      "Epoch 736/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6162 - accuracy: 0.9289 - val_loss: 0.9030 - val_accuracy: 0.8601\n",
      "Epoch 737/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6163 - accuracy: 0.9291 - val_loss: 0.9255 - val_accuracy: 0.8574\n",
      "Epoch 738/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6144 - accuracy: 0.9303 - val_loss: 0.8860 - val_accuracy: 0.8620\n",
      "Epoch 739/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6020 - accuracy: 0.9310 - val_loss: 0.9059 - val_accuracy: 0.8492\n",
      "Epoch 740/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6147 - accuracy: 0.9218 - val_loss: 0.9276 - val_accuracy: 0.8501\n",
      "Epoch 741/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6310 - accuracy: 0.9209 - val_loss: 0.9795 - val_accuracy: 0.8400\n",
      "Epoch 742/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6326 - accuracy: 0.9266 - val_loss: 0.9576 - val_accuracy: 0.8473\n",
      "Epoch 743/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6289 - accuracy: 0.9275 - val_loss: 0.9673 - val_accuracy: 0.8537\n",
      "Epoch 744/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6237 - accuracy: 0.9284 - val_loss: 0.9286 - val_accuracy: 0.8528\n",
      "Epoch 745/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6159 - accuracy: 0.9323 - val_loss: 0.9445 - val_accuracy: 0.8455\n",
      "Epoch 746/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6091 - accuracy: 0.9294 - val_loss: 0.9359 - val_accuracy: 0.8592\n",
      "Epoch 747/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6185 - accuracy: 0.9257 - val_loss: 0.9477 - val_accuracy: 0.8492\n",
      "Epoch 748/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6275 - accuracy: 0.9252 - val_loss: 0.9339 - val_accuracy: 0.8528\n",
      "Epoch 749/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6201 - accuracy: 0.9312 - val_loss: 0.9499 - val_accuracy: 0.8510\n",
      "Epoch 750/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6186 - accuracy: 0.9298 - val_loss: 0.9045 - val_accuracy: 0.8656\n",
      "Epoch 751/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6062 - accuracy: 0.9316 - val_loss: 0.9339 - val_accuracy: 0.8528\n",
      "Epoch 752/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6057 - accuracy: 0.9298 - val_loss: 0.8938 - val_accuracy: 0.8647\n",
      "Epoch 753/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5969 - accuracy: 0.9376 - val_loss: 0.8939 - val_accuracy: 0.8565\n",
      "Epoch 754/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5885 - accuracy: 0.9335 - val_loss: 0.9080 - val_accuracy: 0.8592\n",
      "Epoch 755/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5841 - accuracy: 0.9383 - val_loss: 0.8691 - val_accuracy: 0.8611\n",
      "Epoch 756/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6069 - accuracy: 0.9284 - val_loss: 0.9056 - val_accuracy: 0.8611\n",
      "Epoch 757/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6113 - accuracy: 0.9257 - val_loss: 0.9616 - val_accuracy: 0.8473\n",
      "Epoch 758/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6379 - accuracy: 0.9223 - val_loss: 0.9227 - val_accuracy: 0.8547\n",
      "Epoch 759/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6402 - accuracy: 0.9239 - val_loss: 0.9744 - val_accuracy: 0.8309\n",
      "Epoch 760/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6265 - accuracy: 0.9321 - val_loss: 1.0079 - val_accuracy: 0.8419\n",
      "Epoch 761/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6375 - accuracy: 0.9252 - val_loss: 0.9044 - val_accuracy: 0.8665\n",
      "Epoch 762/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6433 - accuracy: 0.9193 - val_loss: 0.9115 - val_accuracy: 0.8638\n",
      "Epoch 763/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6632 - accuracy: 0.9198 - val_loss: 0.9906 - val_accuracy: 0.8464\n",
      "Epoch 764/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6595 - accuracy: 0.9239 - val_loss: 0.9487 - val_accuracy: 0.8629\n",
      "Epoch 765/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6519 - accuracy: 0.9271 - val_loss: 0.9523 - val_accuracy: 0.8501\n",
      "Epoch 766/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6431 - accuracy: 0.9262 - val_loss: 0.9188 - val_accuracy: 0.8537\n",
      "Epoch 767/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6169 - accuracy: 0.9326 - val_loss: 0.9142 - val_accuracy: 0.8638\n",
      "Epoch 768/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5812 - accuracy: 0.9431 - val_loss: 0.9021 - val_accuracy: 0.8537\n",
      "Epoch 769/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5863 - accuracy: 0.9367 - val_loss: 0.9117 - val_accuracy: 0.8492\n",
      "Epoch 770/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6024 - accuracy: 0.9298 - val_loss: 0.8925 - val_accuracy: 0.8638\n",
      "Epoch 771/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6043 - accuracy: 0.9264 - val_loss: 0.8826 - val_accuracy: 0.8675\n",
      "Epoch 772/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6146 - accuracy: 0.9257 - val_loss: 0.8728 - val_accuracy: 0.8702\n",
      "Epoch 773/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6024 - accuracy: 0.9337 - val_loss: 0.9123 - val_accuracy: 0.8565\n",
      "Epoch 774/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5780 - accuracy: 0.9442 - val_loss: 0.8897 - val_accuracy: 0.8583\n",
      "Epoch 775/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5741 - accuracy: 0.9412 - val_loss: 0.8461 - val_accuracy: 0.8592\n",
      "Epoch 776/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5733 - accuracy: 0.9374 - val_loss: 0.9088 - val_accuracy: 0.8428\n",
      "Epoch 777/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5929 - accuracy: 0.9323 - val_loss: 0.8669 - val_accuracy: 0.8601\n",
      "Epoch 778/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5874 - accuracy: 0.9358 - val_loss: 0.8720 - val_accuracy: 0.8675\n",
      "Epoch 779/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5840 - accuracy: 0.9328 - val_loss: 0.8880 - val_accuracy: 0.8537\n",
      "Epoch 780/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5879 - accuracy: 0.9330 - val_loss: 0.9146 - val_accuracy: 0.8601\n",
      "Epoch 781/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5943 - accuracy: 0.9310 - val_loss: 0.9247 - val_accuracy: 0.8556\n",
      "Epoch 782/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5932 - accuracy: 0.9319 - val_loss: 0.9229 - val_accuracy: 0.8519\n",
      "Epoch 783/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6196 - accuracy: 0.9259 - val_loss: 0.9566 - val_accuracy: 0.8428\n",
      "Epoch 784/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6286 - accuracy: 0.9255 - val_loss: 0.9199 - val_accuracy: 0.8556\n",
      "Epoch 785/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6427 - accuracy: 0.9207 - val_loss: 0.9228 - val_accuracy: 0.8537\n",
      "Epoch 786/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6249 - accuracy: 0.9305 - val_loss: 0.9505 - val_accuracy: 0.8565\n",
      "Epoch 787/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6104 - accuracy: 0.9351 - val_loss: 0.9031 - val_accuracy: 0.8638\n",
      "Epoch 788/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5962 - accuracy: 0.9369 - val_loss: 0.8498 - val_accuracy: 0.8739\n",
      "Epoch 789/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5808 - accuracy: 0.9396 - val_loss: 0.8798 - val_accuracy: 0.8629\n",
      "Epoch 790/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5795 - accuracy: 0.9339 - val_loss: 0.9030 - val_accuracy: 0.8565\n",
      "Epoch 791/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6022 - accuracy: 0.9243 - val_loss: 0.9163 - val_accuracy: 0.8547\n",
      "Epoch 792/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6205 - accuracy: 0.9246 - val_loss: 0.9080 - val_accuracy: 0.8601\n",
      "Epoch 793/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6276 - accuracy: 0.9230 - val_loss: 0.9228 - val_accuracy: 0.8592\n",
      "Epoch 794/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6144 - accuracy: 0.9259 - val_loss: 0.9342 - val_accuracy: 0.8565\n",
      "Epoch 795/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5828 - accuracy: 0.9408 - val_loss: 0.8970 - val_accuracy: 0.8428\n",
      "Epoch 796/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5824 - accuracy: 0.9396 - val_loss: 0.9137 - val_accuracy: 0.8611\n",
      "Epoch 797/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5986 - accuracy: 0.9307 - val_loss: 0.9326 - val_accuracy: 0.8537\n",
      "Epoch 798/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5924 - accuracy: 0.9332 - val_loss: 0.8967 - val_accuracy: 0.8647\n",
      "Epoch 799/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6084 - accuracy: 0.9278 - val_loss: 0.9067 - val_accuracy: 0.8656\n",
      "Epoch 800/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5931 - accuracy: 0.9358 - val_loss: 0.8542 - val_accuracy: 0.8693\n",
      "Epoch 801/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5988 - accuracy: 0.9264 - val_loss: 0.8755 - val_accuracy: 0.8601\n",
      "Epoch 802/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5991 - accuracy: 0.9319 - val_loss: 0.8881 - val_accuracy: 0.8501\n",
      "Epoch 803/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6049 - accuracy: 0.9314 - val_loss: 0.8976 - val_accuracy: 0.8556\n",
      "Epoch 804/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6100 - accuracy: 0.9294 - val_loss: 0.9393 - val_accuracy: 0.8592\n",
      "Epoch 805/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6326 - accuracy: 0.9204 - val_loss: 0.9415 - val_accuracy: 0.8483\n",
      "Epoch 806/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6168 - accuracy: 0.9319 - val_loss: 0.8823 - val_accuracy: 0.8675\n",
      "Epoch 807/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6142 - accuracy: 0.9348 - val_loss: 0.9165 - val_accuracy: 0.8601\n",
      "Epoch 808/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6157 - accuracy: 0.9280 - val_loss: 0.9090 - val_accuracy: 0.8510\n",
      "Epoch 809/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6092 - accuracy: 0.9339 - val_loss: 0.9113 - val_accuracy: 0.8592\n",
      "Epoch 810/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5739 - accuracy: 0.9426 - val_loss: 0.8660 - val_accuracy: 0.8693\n",
      "Epoch 811/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5800 - accuracy: 0.9371 - val_loss: 0.9188 - val_accuracy: 0.8473\n",
      "Epoch 812/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5825 - accuracy: 0.9364 - val_loss: 0.8756 - val_accuracy: 0.8537\n",
      "Epoch 813/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5917 - accuracy: 0.9303 - val_loss: 0.9428 - val_accuracy: 0.8473\n",
      "Epoch 814/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6010 - accuracy: 0.9294 - val_loss: 0.8908 - val_accuracy: 0.8574\n",
      "Epoch 815/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5945 - accuracy: 0.9316 - val_loss: 0.9003 - val_accuracy: 0.8519\n",
      "Epoch 816/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6085 - accuracy: 0.9252 - val_loss: 0.9024 - val_accuracy: 0.8537\n",
      "Epoch 817/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6306 - accuracy: 0.9234 - val_loss: 0.9582 - val_accuracy: 0.8410\n",
      "Epoch 818/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6260 - accuracy: 0.9273 - val_loss: 0.9604 - val_accuracy: 0.8583\n",
      "Epoch 819/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6224 - accuracy: 0.9316 - val_loss: 0.9361 - val_accuracy: 0.8620\n",
      "Epoch 820/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6215 - accuracy: 0.9316 - val_loss: 0.9132 - val_accuracy: 0.8675\n",
      "Epoch 821/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6014 - accuracy: 0.9342 - val_loss: 0.8736 - val_accuracy: 0.8583\n",
      "Epoch 822/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6003 - accuracy: 0.9319 - val_loss: 0.9016 - val_accuracy: 0.8519\n",
      "Epoch 823/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5937 - accuracy: 0.9323 - val_loss: 0.8723 - val_accuracy: 0.8629\n",
      "Epoch 824/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5859 - accuracy: 0.9323 - val_loss: 0.8672 - val_accuracy: 0.8620\n",
      "Epoch 825/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6009 - accuracy: 0.9312 - val_loss: 0.8959 - val_accuracy: 0.8547\n",
      "Epoch 826/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6147 - accuracy: 0.9227 - val_loss: 0.9377 - val_accuracy: 0.8547\n",
      "Epoch 827/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6177 - accuracy: 0.9328 - val_loss: 0.9566 - val_accuracy: 0.8382\n",
      "Epoch 828/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6376 - accuracy: 0.9230 - val_loss: 0.9495 - val_accuracy: 0.8464\n",
      "Epoch 829/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6180 - accuracy: 0.9323 - val_loss: 0.8873 - val_accuracy: 0.8684\n",
      "Epoch 830/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6214 - accuracy: 0.9294 - val_loss: 0.9056 - val_accuracy: 0.8693\n",
      "Epoch 831/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5965 - accuracy: 0.9360 - val_loss: 0.8623 - val_accuracy: 0.8748\n",
      "Epoch 832/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5984 - accuracy: 0.9346 - val_loss: 0.9122 - val_accuracy: 0.8455\n",
      "Epoch 833/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6173 - accuracy: 0.9262 - val_loss: 0.9273 - val_accuracy: 0.8473\n",
      "Epoch 834/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6009 - accuracy: 0.9319 - val_loss: 0.9277 - val_accuracy: 0.8446\n",
      "Epoch 835/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6013 - accuracy: 0.9321 - val_loss: 0.8981 - val_accuracy: 0.8592\n",
      "Epoch 836/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5793 - accuracy: 0.9390 - val_loss: 0.9068 - val_accuracy: 0.8583\n",
      "Epoch 837/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5823 - accuracy: 0.9344 - val_loss: 0.8676 - val_accuracy: 0.8592\n",
      "Epoch 838/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5771 - accuracy: 0.9358 - val_loss: 0.8847 - val_accuracy: 0.8519\n",
      "Epoch 839/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5816 - accuracy: 0.9369 - val_loss: 0.8845 - val_accuracy: 0.8556\n",
      "Epoch 840/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5858 - accuracy: 0.9332 - val_loss: 0.8968 - val_accuracy: 0.8528\n",
      "Epoch 841/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5827 - accuracy: 0.9376 - val_loss: 0.9240 - val_accuracy: 0.8428\n",
      "Epoch 842/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6100 - accuracy: 0.9250 - val_loss: 0.9979 - val_accuracy: 0.8410\n",
      "Epoch 843/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6199 - accuracy: 0.9227 - val_loss: 0.9171 - val_accuracy: 0.8565\n",
      "Epoch 844/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6119 - accuracy: 0.9303 - val_loss: 0.8827 - val_accuracy: 0.8665\n",
      "Epoch 845/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5913 - accuracy: 0.9392 - val_loss: 0.8965 - val_accuracy: 0.8565\n",
      "Epoch 846/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5949 - accuracy: 0.9294 - val_loss: 0.8641 - val_accuracy: 0.8729\n",
      "Epoch 847/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6012 - accuracy: 0.9342 - val_loss: 0.9035 - val_accuracy: 0.8583\n",
      "Epoch 848/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5892 - accuracy: 0.9326 - val_loss: 0.9262 - val_accuracy: 0.8565\n",
      "Epoch 849/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5870 - accuracy: 0.9376 - val_loss: 0.9039 - val_accuracy: 0.8547\n",
      "Epoch 850/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6228 - accuracy: 0.9252 - val_loss: 0.9264 - val_accuracy: 0.8428\n",
      "Epoch 851/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6069 - accuracy: 0.9282 - val_loss: 0.9575 - val_accuracy: 0.8473\n",
      "Epoch 852/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6154 - accuracy: 0.9275 - val_loss: 0.9336 - val_accuracy: 0.8547\n",
      "Epoch 853/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6180 - accuracy: 0.9314 - val_loss: 0.9192 - val_accuracy: 0.8629\n",
      "Epoch 854/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6207 - accuracy: 0.9250 - val_loss: 0.9062 - val_accuracy: 0.8537\n",
      "Epoch 855/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6103 - accuracy: 0.9330 - val_loss: 0.9133 - val_accuracy: 0.8574\n",
      "Epoch 856/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5997 - accuracy: 0.9376 - val_loss: 0.9315 - val_accuracy: 0.8492\n",
      "Epoch 857/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6307 - accuracy: 0.9243 - val_loss: 0.9027 - val_accuracy: 0.8574\n",
      "Epoch 858/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6141 - accuracy: 0.9335 - val_loss: 0.9221 - val_accuracy: 0.8629\n",
      "Epoch 859/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6243 - accuracy: 0.9239 - val_loss: 0.9477 - val_accuracy: 0.8501\n",
      "Epoch 860/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6136 - accuracy: 0.9312 - val_loss: 0.9461 - val_accuracy: 0.8455\n",
      "Epoch 861/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6323 - accuracy: 0.9271 - val_loss: 0.9440 - val_accuracy: 0.8437\n",
      "Epoch 862/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6173 - accuracy: 0.9266 - val_loss: 0.9378 - val_accuracy: 0.8537\n",
      "Epoch 863/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6145 - accuracy: 0.9296 - val_loss: 0.9592 - val_accuracy: 0.8501\n",
      "Epoch 864/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6184 - accuracy: 0.9303 - val_loss: 0.9254 - val_accuracy: 0.8501\n",
      "Epoch 865/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6055 - accuracy: 0.9339 - val_loss: 0.9250 - val_accuracy: 0.8501\n",
      "Epoch 866/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5854 - accuracy: 0.9399 - val_loss: 0.9210 - val_accuracy: 0.8492\n",
      "Epoch 867/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5891 - accuracy: 0.9326 - val_loss: 0.9129 - val_accuracy: 0.8483\n",
      "Epoch 868/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5909 - accuracy: 0.9296 - val_loss: 0.9021 - val_accuracy: 0.8565\n",
      "Epoch 869/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5648 - accuracy: 0.9428 - val_loss: 0.8517 - val_accuracy: 0.8565\n",
      "Epoch 870/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5835 - accuracy: 0.9344 - val_loss: 0.8924 - val_accuracy: 0.8601\n",
      "Epoch 871/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5933 - accuracy: 0.9346 - val_loss: 0.9279 - val_accuracy: 0.8510\n",
      "Epoch 872/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6030 - accuracy: 0.9289 - val_loss: 0.9092 - val_accuracy: 0.8547\n",
      "Epoch 873/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6070 - accuracy: 0.9289 - val_loss: 0.9353 - val_accuracy: 0.8410\n",
      "Epoch 874/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6066 - accuracy: 0.9259 - val_loss: 0.9283 - val_accuracy: 0.8483\n",
      "Epoch 875/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6111 - accuracy: 0.9312 - val_loss: 0.8789 - val_accuracy: 0.8702\n",
      "Epoch 876/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6029 - accuracy: 0.9328 - val_loss: 0.9114 - val_accuracy: 0.8519\n",
      "Epoch 877/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6131 - accuracy: 0.9319 - val_loss: 0.9207 - val_accuracy: 0.8601\n",
      "Epoch 878/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5888 - accuracy: 0.9387 - val_loss: 0.9556 - val_accuracy: 0.8391\n",
      "Epoch 879/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5756 - accuracy: 0.9362 - val_loss: 0.9041 - val_accuracy: 0.8547\n",
      "Epoch 880/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5860 - accuracy: 0.9303 - val_loss: 0.9473 - val_accuracy: 0.8547\n",
      "Epoch 881/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5877 - accuracy: 0.9337 - val_loss: 0.9216 - val_accuracy: 0.8592\n",
      "Epoch 882/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6004 - accuracy: 0.9303 - val_loss: 0.9250 - val_accuracy: 0.8629\n",
      "Epoch 883/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6236 - accuracy: 0.9275 - val_loss: 0.9196 - val_accuracy: 0.8437\n",
      "Epoch 884/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6153 - accuracy: 0.9305 - val_loss: 0.9103 - val_accuracy: 0.8592\n",
      "Epoch 885/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5936 - accuracy: 0.9371 - val_loss: 0.9089 - val_accuracy: 0.8528\n",
      "Epoch 886/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5966 - accuracy: 0.9312 - val_loss: 0.8893 - val_accuracy: 0.8620\n",
      "Epoch 887/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5745 - accuracy: 0.9353 - val_loss: 0.9576 - val_accuracy: 0.8400\n",
      "Epoch 888/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5916 - accuracy: 0.9314 - val_loss: 0.9478 - val_accuracy: 0.8492\n",
      "Epoch 889/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5791 - accuracy: 0.9344 - val_loss: 0.9266 - val_accuracy: 0.8464\n",
      "Epoch 890/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5778 - accuracy: 0.9364 - val_loss: 0.9025 - val_accuracy: 0.8565\n",
      "Epoch 891/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5765 - accuracy: 0.9362 - val_loss: 0.8704 - val_accuracy: 0.8574\n",
      "Epoch 892/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5947 - accuracy: 0.9328 - val_loss: 0.9048 - val_accuracy: 0.8464\n",
      "Epoch 893/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5911 - accuracy: 0.9314 - val_loss: 0.8856 - val_accuracy: 0.8620\n",
      "Epoch 894/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5983 - accuracy: 0.9273 - val_loss: 0.8597 - val_accuracy: 0.8739\n",
      "Epoch 895/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6189 - accuracy: 0.9298 - val_loss: 0.9489 - val_accuracy: 0.8501\n",
      "Epoch 896/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6134 - accuracy: 0.9314 - val_loss: 0.9429 - val_accuracy: 0.8519\n",
      "Epoch 897/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6250 - accuracy: 0.9289 - val_loss: 0.9100 - val_accuracy: 0.8556\n",
      "Epoch 898/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5957 - accuracy: 0.9346 - val_loss: 0.9298 - val_accuracy: 0.8483\n",
      "Epoch 899/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5997 - accuracy: 0.9328 - val_loss: 0.9323 - val_accuracy: 0.8565\n",
      "Epoch 900/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6086 - accuracy: 0.9296 - val_loss: 0.9556 - val_accuracy: 0.8455\n",
      "Epoch 901/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6026 - accuracy: 0.9291 - val_loss: 0.9019 - val_accuracy: 0.8510\n",
      "Epoch 902/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5912 - accuracy: 0.9351 - val_loss: 0.9323 - val_accuracy: 0.8473\n",
      "Epoch 903/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6062 - accuracy: 0.9264 - val_loss: 0.9232 - val_accuracy: 0.8510\n",
      "Epoch 904/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5960 - accuracy: 0.9346 - val_loss: 0.9703 - val_accuracy: 0.8410\n",
      "Epoch 905/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5939 - accuracy: 0.9346 - val_loss: 0.9141 - val_accuracy: 0.8519\n",
      "Epoch 906/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5835 - accuracy: 0.9330 - val_loss: 0.9177 - val_accuracy: 0.8483\n",
      "Epoch 907/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5920 - accuracy: 0.9332 - val_loss: 0.8726 - val_accuracy: 0.8556\n",
      "Epoch 908/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6147 - accuracy: 0.9250 - val_loss: 0.9162 - val_accuracy: 0.8565\n",
      "Epoch 909/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6121 - accuracy: 0.9289 - val_loss: 0.9520 - val_accuracy: 0.8473\n",
      "Epoch 910/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6014 - accuracy: 0.9342 - val_loss: 0.8903 - val_accuracy: 0.8583\n",
      "Epoch 911/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6003 - accuracy: 0.9307 - val_loss: 0.9004 - val_accuracy: 0.8483\n",
      "Epoch 912/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6044 - accuracy: 0.9307 - val_loss: 0.9387 - val_accuracy: 0.8437\n",
      "Epoch 913/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6204 - accuracy: 0.9300 - val_loss: 0.8908 - val_accuracy: 0.8592\n",
      "Epoch 914/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5946 - accuracy: 0.9362 - val_loss: 0.8962 - val_accuracy: 0.8601\n",
      "Epoch 915/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6115 - accuracy: 0.9268 - val_loss: 0.9151 - val_accuracy: 0.8501\n",
      "Epoch 916/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5992 - accuracy: 0.9328 - val_loss: 0.9045 - val_accuracy: 0.8574\n",
      "Epoch 917/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6075 - accuracy: 0.9294 - val_loss: 0.9419 - val_accuracy: 0.8528\n",
      "Epoch 918/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6122 - accuracy: 0.9300 - val_loss: 0.9206 - val_accuracy: 0.8583\n",
      "Epoch 919/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5992 - accuracy: 0.9335 - val_loss: 0.9283 - val_accuracy: 0.8583\n",
      "Epoch 920/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6086 - accuracy: 0.9282 - val_loss: 0.8922 - val_accuracy: 0.8583\n",
      "Epoch 921/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5757 - accuracy: 0.9417 - val_loss: 0.8641 - val_accuracy: 0.8702\n",
      "Epoch 922/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5786 - accuracy: 0.9380 - val_loss: 0.9109 - val_accuracy: 0.8455\n",
      "Epoch 923/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5887 - accuracy: 0.9310 - val_loss: 0.9431 - val_accuracy: 0.8446\n",
      "Epoch 924/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5976 - accuracy: 0.9307 - val_loss: 0.9212 - val_accuracy: 0.8510\n",
      "Epoch 925/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5937 - accuracy: 0.9358 - val_loss: 0.9112 - val_accuracy: 0.8556\n",
      "Epoch 926/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5912 - accuracy: 0.9323 - val_loss: 0.8998 - val_accuracy: 0.8537\n",
      "Epoch 927/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5958 - accuracy: 0.9337 - val_loss: 0.9133 - val_accuracy: 0.8547\n",
      "Epoch 928/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6091 - accuracy: 0.9287 - val_loss: 0.8934 - val_accuracy: 0.8574\n",
      "Epoch 929/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5917 - accuracy: 0.9332 - val_loss: 0.8888 - val_accuracy: 0.8565\n",
      "Epoch 930/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5738 - accuracy: 0.9371 - val_loss: 0.9046 - val_accuracy: 0.8455\n",
      "Epoch 931/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5551 - accuracy: 0.9422 - val_loss: 0.8551 - val_accuracy: 0.8556\n",
      "Epoch 932/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5703 - accuracy: 0.9369 - val_loss: 0.8255 - val_accuracy: 0.8693\n",
      "Epoch 933/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5859 - accuracy: 0.9323 - val_loss: 0.8961 - val_accuracy: 0.8611\n",
      "Epoch 934/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5664 - accuracy: 0.9408 - val_loss: 0.8732 - val_accuracy: 0.8675\n",
      "Epoch 935/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5763 - accuracy: 0.9353 - val_loss: 0.8977 - val_accuracy: 0.8510\n",
      "Epoch 936/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5641 - accuracy: 0.9417 - val_loss: 0.8730 - val_accuracy: 0.8556\n",
      "Epoch 937/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5764 - accuracy: 0.9374 - val_loss: 0.9162 - val_accuracy: 0.8519\n",
      "Epoch 938/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5858 - accuracy: 0.9316 - val_loss: 0.9318 - val_accuracy: 0.8492\n",
      "Epoch 939/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6083 - accuracy: 0.9273 - val_loss: 0.8754 - val_accuracy: 0.8620\n",
      "Epoch 940/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6029 - accuracy: 0.9335 - val_loss: 0.9068 - val_accuracy: 0.8473\n",
      "Epoch 941/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6052 - accuracy: 0.9296 - val_loss: 0.9140 - val_accuracy: 0.8556\n",
      "Epoch 942/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5882 - accuracy: 0.9385 - val_loss: 0.9087 - val_accuracy: 0.8583\n",
      "Epoch 943/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5952 - accuracy: 0.9335 - val_loss: 0.9451 - val_accuracy: 0.8629\n",
      "Epoch 944/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5864 - accuracy: 0.9360 - val_loss: 0.9097 - val_accuracy: 0.8382\n",
      "Epoch 945/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6005 - accuracy: 0.9328 - val_loss: 0.8973 - val_accuracy: 0.8556\n",
      "Epoch 946/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5975 - accuracy: 0.9342 - val_loss: 0.8960 - val_accuracy: 0.8547\n",
      "Epoch 947/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6021 - accuracy: 0.9332 - val_loss: 0.8688 - val_accuracy: 0.8629\n",
      "Epoch 948/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5850 - accuracy: 0.9326 - val_loss: 0.9006 - val_accuracy: 0.8537\n",
      "Epoch 949/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6023 - accuracy: 0.9289 - val_loss: 0.9157 - val_accuracy: 0.8528\n",
      "Epoch 950/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5927 - accuracy: 0.9358 - val_loss: 0.9073 - val_accuracy: 0.8601\n",
      "Epoch 951/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6101 - accuracy: 0.9294 - val_loss: 0.8547 - val_accuracy: 0.8675\n",
      "Epoch 952/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5717 - accuracy: 0.9399 - val_loss: 0.8923 - val_accuracy: 0.8656\n",
      "Epoch 953/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5795 - accuracy: 0.9337 - val_loss: 0.8929 - val_accuracy: 0.8638\n",
      "Epoch 954/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5849 - accuracy: 0.9362 - val_loss: 0.9216 - val_accuracy: 0.8519\n",
      "Epoch 955/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6273 - accuracy: 0.9303 - val_loss: 0.9641 - val_accuracy: 0.8291\n",
      "Epoch 956/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6185 - accuracy: 0.9321 - val_loss: 0.9237 - val_accuracy: 0.8519\n",
      "Epoch 957/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5996 - accuracy: 0.9353 - val_loss: 0.9308 - val_accuracy: 0.8528\n",
      "Epoch 958/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6006 - accuracy: 0.9307 - val_loss: 0.9551 - val_accuracy: 0.8483\n",
      "Epoch 959/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5998 - accuracy: 0.9323 - val_loss: 0.9397 - val_accuracy: 0.8510\n",
      "Epoch 960/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5998 - accuracy: 0.9316 - val_loss: 0.9254 - val_accuracy: 0.8501\n",
      "Epoch 961/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5936 - accuracy: 0.9310 - val_loss: 0.9312 - val_accuracy: 0.8638\n",
      "Epoch 962/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5961 - accuracy: 0.9332 - val_loss: 0.9428 - val_accuracy: 0.8492\n",
      "Epoch 963/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6049 - accuracy: 0.9287 - val_loss: 0.9609 - val_accuracy: 0.8492\n",
      "Epoch 964/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5895 - accuracy: 0.9339 - val_loss: 0.9284 - val_accuracy: 0.8565\n",
      "Epoch 965/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6037 - accuracy: 0.9307 - val_loss: 0.9357 - val_accuracy: 0.8519\n",
      "Epoch 966/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5999 - accuracy: 0.9353 - val_loss: 0.8968 - val_accuracy: 0.8601\n",
      "Epoch 967/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6050 - accuracy: 0.9287 - val_loss: 0.9087 - val_accuracy: 0.8473\n",
      "Epoch 968/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5898 - accuracy: 0.9351 - val_loss: 0.9108 - val_accuracy: 0.8565\n",
      "Epoch 969/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5902 - accuracy: 0.9360 - val_loss: 0.8820 - val_accuracy: 0.8547\n",
      "Epoch 970/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5917 - accuracy: 0.9332 - val_loss: 0.8792 - val_accuracy: 0.8629\n",
      "Epoch 971/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.5709 - accuracy: 0.9417 - val_loss: 0.8783 - val_accuracy: 0.8638\n",
      "Epoch 972/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5694 - accuracy: 0.9383 - val_loss: 0.9039 - val_accuracy: 0.8510\n",
      "Epoch 973/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5790 - accuracy: 0.9358 - val_loss: 0.9117 - val_accuracy: 0.8537\n",
      "Epoch 974/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5932 - accuracy: 0.9326 - val_loss: 0.9087 - val_accuracy: 0.8611\n",
      "Epoch 975/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5845 - accuracy: 0.9342 - val_loss: 0.8810 - val_accuracy: 0.8611\n",
      "Epoch 976/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5937 - accuracy: 0.9312 - val_loss: 0.9490 - val_accuracy: 0.8382\n",
      "Epoch 977/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6077 - accuracy: 0.9298 - val_loss: 0.9714 - val_accuracy: 0.8391\n",
      "Epoch 978/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5939 - accuracy: 0.9339 - val_loss: 0.8960 - val_accuracy: 0.8647\n",
      "Epoch 979/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5976 - accuracy: 0.9328 - val_loss: 0.9026 - val_accuracy: 0.8638\n",
      "Epoch 980/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5965 - accuracy: 0.9266 - val_loss: 0.9111 - val_accuracy: 0.8565\n",
      "Epoch 981/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6014 - accuracy: 0.9360 - val_loss: 0.9089 - val_accuracy: 0.8574\n",
      "Epoch 982/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5867 - accuracy: 0.9390 - val_loss: 0.8891 - val_accuracy: 0.8601\n",
      "Epoch 983/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.5856 - accuracy: 0.9346 - val_loss: 0.8846 - val_accuracy: 0.8547\n",
      "Epoch 984/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5766 - accuracy: 0.9367 - val_loss: 0.9279 - val_accuracy: 0.8446\n",
      "Epoch 985/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5785 - accuracy: 0.9342 - val_loss: 0.8802 - val_accuracy: 0.8601\n",
      "Epoch 986/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5725 - accuracy: 0.9383 - val_loss: 0.8611 - val_accuracy: 0.8684\n",
      "Epoch 987/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5741 - accuracy: 0.9403 - val_loss: 0.9022 - val_accuracy: 0.8519\n",
      "Epoch 988/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5834 - accuracy: 0.9282 - val_loss: 0.8836 - val_accuracy: 0.8611\n",
      "Epoch 989/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5918 - accuracy: 0.9312 - val_loss: 0.8901 - val_accuracy: 0.8492\n",
      "Epoch 990/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6021 - accuracy: 0.9273 - val_loss: 0.9519 - val_accuracy: 0.8492\n",
      "Epoch 991/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6043 - accuracy: 0.9339 - val_loss: 0.9803 - val_accuracy: 0.8455\n",
      "Epoch 992/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6049 - accuracy: 0.9344 - val_loss: 0.9262 - val_accuracy: 0.8611\n",
      "Epoch 993/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6251 - accuracy: 0.9282 - val_loss: 0.8882 - val_accuracy: 0.8739\n",
      "Epoch 994/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6326 - accuracy: 0.9232 - val_loss: 0.9187 - val_accuracy: 0.8592\n",
      "Epoch 995/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6035 - accuracy: 0.9348 - val_loss: 0.9713 - val_accuracy: 0.8464\n",
      "Epoch 996/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6146 - accuracy: 0.9314 - val_loss: 0.9099 - val_accuracy: 0.8592\n",
      "Epoch 997/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6085 - accuracy: 0.9335 - val_loss: 0.9701 - val_accuracy: 0.8446\n",
      "Epoch 998/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6119 - accuracy: 0.9307 - val_loss: 0.9011 - val_accuracy: 0.8583\n",
      "Epoch 999/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5942 - accuracy: 0.9339 - val_loss: 0.9007 - val_accuracy: 0.8665\n",
      "Epoch 1000/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6013 - accuracy: 0.9319 - val_loss: 0.9190 - val_accuracy: 0.8519\n",
      "CPU times: total: 4min 54s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 200\n",
    "epochs = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train, y_train,\n",
    "  batch_size=batch_size,\n",
    "  epochs=epochs,\n",
    "  validation_split=0.2,\n",
    "  shuffle=True,\n",
    "  # callbacks=[model_checkpoint_callback, lrate_scheduler_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accuracy: 0.932\n",
      "train loss: 0.601\n",
      "validation set accuracy: 0.852\n",
      "validation set loss: 0.919\n"
     ]
    }
   ],
   "source": [
    "length = len(history.history['accuracy'])\n",
    "print(\"train set accuracy:\", round(history.history['accuracy'][length-1], 3))\n",
    "print(\"train loss:\", round(history.history['loss'][length-1], 3))\n",
    "print(\"validation set accuracy:\", round(history.history['val_accuracy'][length-1], 3))\n",
    "print(\"validation set loss:\", round(history.history['val_loss'][length-1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9557 - accuracy: 0.8639\n",
      "test set accuracy: 0.864\n",
      "test set loss: 0.956\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test set accuracy:\", round(results[1], 3))\n",
    "print(\"test set loss:\", round(results[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
